import torch
from ..utils.logging import get_logger as get_logger
from _typeshed import Incomplete
from careamics.config.support import SupportedOptimizer as SupportedOptimizer, SupportedScheduler as SupportedScheduler

logger: Incomplete

def filter_parameters(func: type, user_params: dict) -> dict: ...
def get_optimizer(name: str) -> torch.optim.Optimizer: ...
def get_optimizers() -> dict[str, str]: ...
def get_scheduler(name: str) -> torch.optim.lr_scheduler.ReduceLROnPlateau: ...
def get_schedulers() -> dict[str, str]: ...
