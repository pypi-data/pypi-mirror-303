import ml_collections
import pytorch_lightning as L
import torch
from .metrics import RangeInvariantPsnr as RangeInvariantPsnr, RunningPSNR as RunningPSNR
from .train_utils import MetricMonitor as MetricMonitor
from _typeshed import Incomplete
from careamics.models.lvae.likelihoods import LikelihoodModule as LikelihoodModule
from careamics.models.lvae.lvae import LadderVAE as LadderVAE
from careamics.models.lvae.utils import LossType as LossType, compute_batch_mean as compute_batch_mean, free_bits_kl as free_bits_kl, torch_nanmean as torch_nanmean
from typing import Any

class LadderVAELight(L.LightningModule):
    data_mean: Incomplete
    data_std: Incomplete
    target_ch: Incomplete
    model: Incomplete
    workdir: Incomplete
    kl_loss_formulation: Incomplete
    loss_type: Incomplete
    channel_1_w: int
    channel_2_w: int
    reconstruction_mode: bool
    skip_nboundary_pixels_from_loss: Incomplete
    reconstruction_weight: float
    ch1_recons_w: int
    ch2_recons_w: int
    enable_mixed_rec: bool
    mixed_rec_w_step: int
    kl_weight: float
    usplit_kl_weight: Incomplete
    free_bits: float
    kl_annealing: bool
    kl_annealtime: Incomplete
    kl_start: int
    lr: Incomplete
    lr_scheduler_patience: Incomplete
    lr_scheduler_monitor: Incomplete
    lr_scheduler_mode: Incomplete
    channels_psnr: Incomplete
    def __init__(self, config: ml_collections.ConfigDict, data_mean: dict[str, torch.Tensor], data_std: dict[str, torch.Tensor], target_ch: int) -> None: ...
    def forward(self, x: Any) -> Any: ...
    def training_step(self, batch: torch.Tensor, batch_idx: int, enable_logging: bool = True) -> dict[str, torch.Tensor]: ...
    def validation_step(self, batch: torch.Tensor, batch_idx: int): ...
    mixed_rec_w: Incomplete
    def on_validation_epoch_end(self) -> None: ...
    def predict_step(self, batch: torch.Tensor, batch_idx: Any) -> Any: ...
    def configure_optimizers(self): ...
    def get_reconstruction_loss(self, reconstruction: torch.Tensor, target: torch.Tensor, input: torch.Tensor, splitting_mask: torch.Tensor = None, return_predicted_img: bool = False, likelihood_obj: LikelihoodModule = None) -> dict[str, torch.Tensor]: ...
    def reconstruction_loss_musplit_denoisplit(self, out, target_normalized): ...
    def get_kl_weight(self): ...
    def get_kl_divergence_loss_usplit(self, topdown_layer_data_dict: dict[str, torch.Tensor]) -> torch.Tensor: ...
    def get_kl_divergence_loss(self, topdown_layer_data_dict, kl_key: str = 'kl'): ...
    def normalize_input(self, x): ...
    def normalize_target(self, target, batch: Incomplete | None = None): ...
    def unnormalize_target(self, target_normalized): ...
    @property
    def global_step(self) -> int: ...
    def increment_global_step(self) -> None: ...
    def set_params_to_same_device_as(self, correct_device_tensor: torch.Tensor): ...
    def get_mixed_prediction(self, prediction, prediction_logvar, data_mean, data_std, channel_weights: Incomplete | None = None): ...
