{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the parquetfile we saved in notebook 1. You will need to change the filename in the config file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "configfile = Path(\"../config.toml\").resolve()\n",
    "with configfile.open(\"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"..\").resolve()\n",
    "processed = root / Path(config[\"processed\"])\n",
    "datafile = processed / config[\"current\"]\n",
    "if not datafile.exists():\n",
    "    logger.warning(f\"{datafile} does not exist. First run src/preprocess.py, and check the timestamp!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how datatypes have been preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(datafile)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the amount of messages, per author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = df[['author', 'message']].\\\n",
    "    groupby(\"author\").\\\n",
    "    count().\\\n",
    "    sort_values(\"message\", ascending=False)\n",
    "\n",
    "k = 15\n",
    "topk = p1[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_authors = list(topk.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_topk\"] = df[\"author\"].apply(lambda x: x in topk_authors)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(y=p1.index[:k], x=\"message\", data=topk);\n",
    "plt.xticks(rotation=90);\n",
    "plt.title(\"Sending the most messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe tweak the colors a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [0 if x < 1000 else 1 for x in topk.message]\n",
    "custom_palette = {0: \"grey\", 1: \"red\"}\n",
    "sns.barplot(y=p1.index[:k], x=\"message\", hue=colors, data=topk, palette=custom_palette, legend=False);\n",
    "plt.title(\"Sending the most messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average message length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message_length'] = df['message'].str.len()\n",
    "p1 = df[['author', 'message_length']].\\\n",
    "    groupby(\"author\").\\\n",
    "    mean().\\\n",
    "    sort_values(\"message_length\", ascending=False)\n",
    "k=15\n",
    "topk = p1[1:k]\n",
    "sns.barplot(y=p1.index[1:k], x=\"message_length\", data=topk);\n",
    "plt.xlabel(\"Average message length\")\n",
    "plt.title(\"Sending the longest messages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple regex to look for links in the messages and add that as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_link = r\"http\"\n",
    "df['has_link'] = df['message'].str.contains(has_link)\n",
    "p1 = df[['author', 'has_link']].\\\n",
    "    groupby(\"author\").\\\n",
    "    mean().\\\n",
    "    sort_values(\"has_link\", ascending=False)\n",
    "\n",
    "k=15\n",
    "topk = p1[:k]\n",
    "sns.barplot(y=p1.index[:k], x=\"has_link\", data=topk)\n",
    "plt.xlabel(\"Fraction of messages with a link\")\n",
    "plt.title(\"Most links by...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the emojis per user (can you change between sum and mean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = df[['author', 'has_emoji']].\\\n",
    "    groupby('author').\\\n",
    "    agg(['sum', 'mean']).\\\n",
    "    sort_values(('has_emoji', 'sum'), ascending=False)\n",
    "\n",
    "p2.columns = p2.columns.droplevel(0)\n",
    "topk = p2[:k]\n",
    "sns.barplot(y=p2.index[:k], x=\"mean\", data=topk)\n",
    "plt.xlabel(\"Average number of messages with an emoji\")\n",
    "plt.title(\"Are emoji's non-verbal?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a cateory, based on the time when authors send a message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define the time ranges\n",
    "time_ranges = ['00:00', '06:00', '08:00', '17:30', '22:00', '23:59']\n",
    "# Define the category labels\n",
    "categories = ['night', 'morning', 'worktimes', 'evening', 'late']\n",
    "# Categorize the timestamp column\n",
    "df['timestamp_category'] = pd.cut(df['timestamp'].dt.time.astype(str), bins=time_ranges, labels=categories, right=False)\n",
    "# Display the updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can group and count the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by 'author' and 'timestamp_category', and count the occurrences\n",
    "p3 = df.groupby(['author', 'timestamp_category']).size().unstack()\n",
    "\n",
    "# Calculate the fraction of each category for every author\n",
    "p3_frac = p3.div(p3.sum(axis=1), axis=0)\n",
    "p3_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use plotly the create a stacked bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = p3_frac.reset_index().melt(id_vars='author')\n",
    "p4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_filtered = p4[p4['author'].isin(topk_authors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(p4_filtered, y=\"author\", x=\"value\", color=\"timestamp_category\", barmode=\"stack\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the minimum and maximum time of the messages for every author, and convert that to a decimal fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].dt.time\n",
    "summary_df = df.groupby('author')['hour'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "def convert_to_decimal_hours(timestamp):\n",
    "    dec_hour = timestamp.hour + timestamp.minute / 60 + timestamp.second / 3600\n",
    "    return dec_hour\n",
    "\n",
    "summary_df['min_x_values'] = summary_df['min'].apply(convert_to_decimal_hours)\n",
    "summary_df['max_x_values'] = summary_df['max'].apply(convert_to_decimal_hours)\n",
    "\n",
    "# Drop the original 'min' and 'max' columns as they are no longer needed\n",
    "summary_df = summary_df.drop(['min', 'max'], axis=1)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can create a nice barbell chart. Try to add colors for your own chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create scatter plots\n",
    "sns.scatterplot(data=summary_df, x='min_x_values', y='author', color='grey')\n",
    "sns.scatterplot(data=summary_df, x='max_x_values', y='author', color='grey')\n",
    "\n",
    "# Add lines\n",
    "for index, row in summary_df.iterrows():\n",
    "    plt.plot([row['min_x_values'], row['max_x_values']], [row['author'], row['author']], color='grey')\n",
    "\n",
    "\n",
    "# Adjust the font size of the y-axis labels if needed\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach for comparing is to create a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "author_day_counts = df.groupby(['author', 'day_of_week']).size().unstack(fill_value=0)\n",
    "author_day_percentages = author_day_counts.div(author_day_counts.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "filtered = author_day_percentages.loc[topk_authors]\n",
    "sns.heatmap(filtered, annot=True, fmt=\".2f\", linewidths=.5, cmap=\"vlag\")\n",
    "plt.xticks(ticks=range(7), labels=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], rotation=45)\n",
    "plt.title(\"Heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the new features we added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(datafile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
