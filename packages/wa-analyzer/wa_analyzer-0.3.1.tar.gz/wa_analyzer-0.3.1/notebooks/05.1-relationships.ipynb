{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "configfile = Path(\"../config.toml\").resolve()\n",
    "with configfile.open(\"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "datafile = (Path(\"..\") / Path(config[\"processed\"]) / config[\"current\"]).resolve()\n",
    "if not datafile.exists():\n",
    "    logger.warning(\"Datafile does not exist. First run src/preprocess.py, and check the timestamp!\")\n",
    "df = pd.read_parquet(datafile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_decimal_hours(timestamp):\n",
    "    dec_hour = timestamp.hour + timestamp.minute / 60 + timestamp.second / 3600\n",
    "    return dec_hour\n",
    "\n",
    "df[\"hour\"] = df[\"timestamp\"].apply(convert_to_decimal_hours)\n",
    "df[\"log_len\"] = df[\"message_length\"].apply(lambda x: np.log(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"hour\", y=\"log_len\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.groupby([\"author\"]).agg({\n",
    "    \"message_length\": \"mean\",\n",
    "    \"has_emoji\": \"mean\",\n",
    "    \"author\": \"count\"\n",
    "}).rename(columns={\"author\": \"count\"})\n",
    "\n",
    "p = p[p[\"count\"] > 10]\n",
    "sns.scatterplot(data=p, x=\"message_length\", y=\"has_emoji\", alpha=0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=p, x=\"message_length\", y=\"has_emoji\", size=\"count\", sizes=(10, 500), alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[\"message_length\"] /= p[\"message_length\"].max()\n",
    "p[\"has_emoji\"] /= p[\"has_emoji\"].max()\n",
    "p[\"color\"] = p.apply(lambda x: \"grey\" if x[\"message_length\"] > x[\"has_emoji\"] else \"red\", axis=1)\n",
    "\n",
    "sns.scatterplot(data=p, y=\"message_length\", x=0, color=\"grey\")\n",
    "sns.scatterplot(data=p, y=\"has_emoji\", x=1, color=\"grey\")\n",
    "for index, row in p.iterrows():\n",
    "    sns.lineplot(x=[0, 1], y=[row[\"message_length\"], row[\"has_emoji\"]], color=row[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The map is not the terrain\n",
    "\n",
    "A model is always an inaccurate representation of reality. That is not a problem, but a useful feature: the simplification of reality allows us to spot patterns and trends that might otherwise be lost in the details.\n",
    "\n",
    "The problem is that simplifying reality always carries the risk of bending the truth to fit your story, but it isn't always obvious which model is the \"best\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "penguinsdataset = DatasetFactoryProvider.create_factory(\n",
    "    DatasetType.PENGUINS\n",
    ")\n",
    "penguinsdataset.download_data()\n",
    "\n",
    "df = pd.read_parquet(penguinsdataset.filepath)\n",
    "select = [\n",
    "    \"Species\",\n",
    "    \"Island\",\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "    \"Delta 15 N (o/oo)\",\n",
    "    \"Delta 13 C (o/oo)\",\n",
    "    \"Sex\",\n",
    "    \"Body Mass (g)\",\n",
    "]\n",
    "subset = df[select].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=subset, x=\"Culmen Length (mm)\", y=\"Body Mass (g)\", fit_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "x = subset[\"Culmen Length (mm)\"]\n",
    "y = subset[\"Body Mass (g)\"]\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print(f\"The model is y = {slope:.2f}x + {intercept:.2f}, with R^2 = {r_value**2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=subset, x=\"Culmen Length (mm)\", y=\"Body Mass (g)\", order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = np.polyfit(x, y, 2)\n",
    "print(f\"The model is {model[0]:.2f}x^2 + {model[1]:.2f}x + {model[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=subset, x=\"Culmen Length (mm)\", y=\"Body Mass (g)\", logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(np.log(x), y)\n",
    "print(f\"The model is y = {slope:.2f} log(x) + {intercept:.2f}, with R^2 = {r_value**2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=subset, x=\"Culmen Length (mm)\", y=\"Body Mass (g)\", lowess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowess stands for Locally Weighted Scatterplot Smoothing, and it is a non-parametric regression method that fits a smooth curve to the data. It is a useful tool to explore the relationship between two variables, but it is not a model in the traditional sense. It is a tool to help us understand the data, not to make predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
