Hoi, leuk dat je weer luistert naar een nieuwe aflevering van AIToday Live. Met vandaag de gast Tamara Thuis. Tamara gaat ons van alles vertellen over ethiek, maar vooral eigenlijk ook over een maturity model. En dat klinkt wel heel praktisch en dat is altijd heel erg leuk. Mijn naam Joop Snijder, CTO bij Aigency. Mijn naam Niels Naglé, Area Lead Data & AI bij Info Support. Tamara, dank je wel dat je hier wilde komen. Ja, leuker om hier te zijn. Ja, zou je je willen voorstellen aan onze luisteraars? Ja, ik ben Tamara Thuis. Ik ben een promovendus aan de Erasmus Universiteit. Binnen de Erasmus Universiteit zit ik bij de Business School, dat is de Rotterdam School of Management. En daar doe ik onderzoek naar de ethische aspecten van AI. Ja. Misschien wel algoritmes in het algemeen. Ja. Dat is goed om erbij te zitten. En dan geef ik ook les over aan studenten. Voornamelijk vanuit een organisatorisch perspectief. Dus hoe kunnen organisaties dat nou toepassen in de praktijk? En wat komt er nou bij kijken? En waar lopen ze nou tegen aan? Ja. En daarnaast ben ik ook medeoprichter van de Ethische Data Science Associatie, samen met Joris Krijger, ook een PhD aan de Erasmus Universiteit. En wat we eigenlijk daar doen is kennisdeling faciliteren rondom dit onderwerp. En ervoor zorgen dat bedrijven van elkaar kunnen leren op dit aspect. En daardoor eigenlijk het hele veld verder kunnen brengen. En de implementatie van de ethiek kunnen vergroten. Dus nou. Goed initiatief. Leuk. Ja, heel goed initiatief. Misschien toch nog even over dat laatste even doorvragen. Want hoe ziet dat leren van elkaar eruit? Ja, dat noemen wij mutual learning. Ik moet eerlijk zeggen dat is niet iets wat wij zelf hebben bedacht. Maar dat is iets wat Huub Zwart, dat is de decaan van de Filosofiefaculteit, al een jaar heeft toegepast in nanoethiek. En dat gaat eigenlijk over dat mensen bloot worden gesteld aan meningen, zorgen, implicaties vanuit verschillende perspectieven. En dat hebben we eigenlijk proberen toe te passen op die AI en ethiek context. Dus we zijn begonnen met een pilot eigenlijk in corona. Ja. En zijn eigenlijk bedrijven gaan uitnodigen die hiermee aan de slag gaan. Want wat wij zagen is dat er heel veel forums waren, plekken om ethiek te bespreken. Maar er zijn heel weinig plekken waar je ook echt ziet wat er daadwerkelijk in de praktijk gebeurt om dat aan te pakken. Dus waarmee wij zijn begonnen is om één bedrijf te vragen van "Kan jij eens presenteren hoe jij dat nou in de praktijk hebt opgezet? Waar ben je nou begonnen? Wat voor problematiek liep je tegenaan in de praktijk wanneer je een algoritme ging toepassen? Kan je die aanpak nou eens laten zien?" En dan hebben we ook experts van andere organisaties uitgenodigd. Dat doen we altijd op een hele kleine schaal. Dus max 12, 15 mensen in één sessie. Want dan krijg je namelijk ook die mutual learning. Als je 100 mensen in een call zet, dan is het vaak zenden en luisteren. Want je zegt de call, dus het was ook in covid, dus het was allemaal digitaal. Ja, het was allemaal digitaal. Het was nog die pilot. Dus je wilt dat mutual hebben. Je wilt dat iedereen iets kan bijdragen aan die sessie. Betekent dat dan dat iedereen tussen aanhalingstekens ook een andere expertise-achtergrond heeft? Ja, precies. Dus wij nodigen een diverse groep stakeholders uit. Dus dat hoeven niet alleen maar technici te zijn, maar dat kunnen ook beleidsmakers, onderzoekers, mensen met een legal achtergrond. Eigenlijk zo divers mogelijk als dat kan binnen die 12, 15 man die je uitnodigt. Heb je daar een voorbeeld van, misschien zonder het bedrijf te noemen, maar een bepaalde casus als voorbeeld? Ja, ik denk dat wij in die twee, drie jaar waar we die sessies hebben georganiseerd, verschillende typen onderwerpen hadden die we bespraken. Dus soms zie je dat er een afweging is tussen twee principes, die heel moeilijk op te lossen is in de praktijk. Denk bijvoorbeeld aan een afweging tussen privacy en fairness. Hoe ga je daar nou mee om? Dat is een voorbeeld dat je vaak ziet bij verzekeringsbedrijven. Kan je voor de luisteraar uitleggen waar dat elkaar bijt? Ja, vaak kunnen er bepaalde biases of ethische implicaties ontstaan op het moment dat je een algoritme gebruikt. Dat betekent eigenlijk dat misschien bepaalde bevolkingsgroepen of mensen met bepaalde karakteristieken eigenlijk benadeeld worden door dat algoritme. Dat kan ook verschillende oorzaken hebben. Dat kan komen door de data, dat kan komen door misschien bepaalde percepties dat ontwikkelaars hebben bij het maken van dat algoritme. Dat kan ook liggen aan het type organisatie of de context. Altijd heel erg contextueel wat voor problemen er ontstaan bij algoritmes. En op het moment dat je zo'n bias wil oplossen, wil je eigenlijk weten wie wordt er nou benadeeld. Je wil inzicht krijgen in wie nou diegenen zijn die worden benadeeld. En om die mensen te kunnen identificeren moet je dus ook gegevens over die mensen verzamelen. Mogelijk privacygevoelige gegevens. Precies. Dus hoe ga je daar nou mee om? En hoe zorg je er ook voor dat de mensen die juist wil helpen, dat dat niet degenen zijn die daar de dupe van worden. En dat niet de mensen zijn die dan juist heel veel privégegevens moeten delen met het soort bedrijven om zo'n probleem op te lossen. En dat is natuurlijk vrij ingewikkeld. Dat is zeker vrij ingewikkeld, ja. Dat is één voorbeeld. En het andere is dat het dus echt een afweging tussen twee principes is. Dat zie je natuurlijk ook vaker. Dat als we het hebben over ethiek, dat er altijd een afweging is tussen twee aspecten. En die moet je in balans houden. En daarom is er ook vaak nooit één juiste antwoord. Maar je zit net het perspectief dat je aanneemt, of vanuit het perspectief dat je het bekijkt, hoe je dat probleem of die afweging aanvliegt. Mag ik daar nog iets over doorvragen? Want hoe weeg je dan de perspectieven af? Dat is dus ook wat we hebben geprobeerd in die sessies. Je gaat echt een dialoog met elkaar aan. Het is een dialectic proces. Ethiek gaat niet alleen maar over de uitkomst. Ethiek gaat niet over 'wat beslissen we nou met elkaar?' en 'wat is nou het juiste?' Maar het gaat juist om het proces dat je leert hoe andere mensen over bepaalde aspecten, afwegingen en problematiek denken. Dus er zit een intrinsieke waarde in het proces ethiek en een instrumentele waarde. Dus die instrumentele waarde gaat over de keuze die je daadwerkelijk maakt. En de intrinsieke waarde gaat veel meer over 'oké, maar hoe kijken andere mensen er nou naar?' En dat zie je natuurlijk vaker in filosofie. Ik heb ook filosofie gestudeerd. En dat vond ik heel leuk om dat naast iets zoals bedrijfskunde te doen. Want bij bedrijfskunde krijg je vaak één perspectief, één model, een framework. En wat ik in mijn filosofie-studie heel erg leerde, is dat er meerdere perspectieven zijn om naar één aspect te kijken. En dat is precies ook wat je in die ethische afweging doet. En betekent dat dat je daardoor ook, door die verschillende perspectieven te horen, dat je je eigen blinde vlekken, zeg maar, in ieder geval een beetje opgevuld ziet worden? Bijvoorbeeld, ja. Daar is een diverse groep dan ook wel noodzakelijk voor. Een vraag die bij mij dan komt op is, leuk dat je het gesprek daarover hebt, maar hoe ga je dat ook borgen en weer uitdragen? Dus ik denk dat je dan al veel meer naar de organisatorische, dat noemen wij dan operationalisatie, gaat. En dat is denk ik ook precies het probleem, maar de uitdaging die we denk ik op dit moment hebben, is dat er heel veel principes zijn, er zijn heel veel tooling, methode, denk aan alles rondom fairness, metrics, explainability methodes. Maar hoe borg je dat nou op een systematische manier in een organisatie? En dat is onder andere waar ik ook zelf onderzoek naar doe. Maar dat zijn denk ik ook vragen, dus we willen met die sessies, met die mutual learning sessies, niet alleen maar aantonen wat zijn nou die problemen en die uitdagingen, maar ook hoe heb je dat nou geborgd? En daarom is het zo belangrijk dat het een kleine groep mensen is, waarin een bedrijf of een organisatie daadwerkelijk de aanpak toont. Want dan kun je namelijk ook concreet feedback geven op hoe dat is aangepakt, en hoe jij dat misschien vanuit jouw perspectief anders zou hebben gedaan. Dus in onze sessies staat de gebruikerscontext altijd centraal. Dus we hebben het niet over fairness en privacy in het algemeen, maar altijd in die specifieke context waarin de organisatie er tegenaan is gelopen. Dat is dan de why, maar ook dat je echt de how, dus de hoe, ook met elkaar bespreekt, zodat je ook de hoe kan bepalen, want wie weet is de uitkomst heel erg valide of niet valide. Maar hoe ben je daartoe gekomen en hoe heb je dat aangepakt om dat echt te bespreken met elkaar? En dat is ook denk ik mooi aan het organisatorische perspectief, want je ziet dat ethiek wordt heel vaak vanuit een filosofisch perspectief bekeken, dus dan heb je juist die verschillende perspectieven, verschillende ethische theorieën die je daarop kan toepassen. Het wordt vaak vanuit een technisch perspectief bekeken, hoe kun je nou technisch een algoritme uitlegbaar maken. Maar om het structureel en systematisch te bekijken, is het ook nodig om daar een organisatorisch perspectief aan toe te voegen, en ervoor te zorgen dat die oplossingen, die filosofische methode, maar ook die technische methode in de structuren, processen en praktijken van organisaties worden, nou ja, 'embedded' in het Engels. -Opgenomen. -Opgenomen. -Omarmd. -Nou ja, en in misschien wel de bestaande structuren van een organisatie worden geïntegreerd. Want vaak is er al heel veel, vaak zijn er al bepaalde processen, en is dat stukje algoritme nog iets wat daar ontbreekt. -Ik ben wel benieuwd zo direct van hoe dat dan gaat, maar ik heb dan nog een vraag daartussenin. Vinden organisaties dit niet moeilijk om zo ontleed te worden? -Ja, dat is niet altijd makkelijk. Maar die kwetsbaarheid, want ik noem het een bepaalde kwetsbaarheid, denk ik, want je moet heel eerlijk zijn over hoe je dingen hebt aangepakt, en ik denk dat elke organisatie daar ook zijn eigen balans in wint. Dus we hebben bijvoorbeeld voorbeelden gezien waar ze wel heel open zijn over de aanpak, maar bijvoorbeeld details over het algoritme. Dus bijvoorbeeld gezegd, er worden zoveel features gebruikt, maar niet precies welke features. Dat maakt de discussie soms ook wel lastiger. -Want het aantal zegt eigenlijk niks. Dat ze nou tien zijn of duizend. -Precies, ja. Maar dat is ook aan de organisatie zelf in hoeverre ze daar open in de leng kunnen zijn soms. Maar wat we hebben ervaren, en ik denk ook, we hebben daarna ook een fysiek event georganiseerd, en daar zie je ook, de kwetsbaarheid levert ook iets moois op en versterkt eigenlijk dat mutual learning effect. Dat maakt het eigenlijk effectiever, want waarschijnlijk zijn er organisaties die precies dezelfde vraagstukken hebben. En dat is ook altijd ons doel geweest, dat het heel zonde zou zijn als op zo'n maatschappelijk onderwerp eigenlijk iedereen het wiel opnieuw gaat uitvinden. -Dat is zeker een belangrijke. En het integreren in de organisatie, zeg jij, hoe moet ik dat voor me zien? -Als je kijkt naar dat organisatieperspectief, het gaat altijd meer over relationele en procedurele aspecten. Dus wat zijn de relaties tussen verschillende rollen in een organisatie, hoe zien de verantwoordelijkheidsstructuren eruit, wat voor processen ga je in. Dus om wat meer voorbeelden daar aan te geven, bijvoorbeeld stel je voor je implementeert een fairness metric. En daar komt een bepaalde uitkomst uit. En dan? Is dat dan goed? Is dat dan slecht? Wat betekent dat nou? Dus je wilt een bepaalde structuur of proces inrichten, dus bijvoorbeeld een structuur waarvan je zegt van "hé, we hebben deze uitkomst, willen graag dat deze en deze personen of deze en deze rollen daarna gaan kijken." En die geven daar of een advies over of die bepalen wat daarmee gedaan moet worden. Dus dat is meer een voorbeeld van een structuur. Een voorbeeld van een proces kan ook zijn van "hé, we gaan eerst uitrekenen wat die metric is, dan de volgende stap in het proces is dat we dat gaan evalueren en daarna gaan we het algoritme weer aanpassen op de manier hoe we daar besloten hebben." Dus het implementeren van zo'n technische oplossing is één, maar wat doe je er dan mee? En daarvoor heb je dat organisatorische... Ja, die begrijp ik helemaal. En zeker want, net wat je zegt, je kan het wel meten, maar wat nou als er inderdaad iets uitkomt wat ongewenst is, wat doe je er dan mee? Ja, en hetzelfde, mijn eigen onderzoek gaat onder andere over uitlegbaarheid. Daar kan ik dadelijk wat meer over vertellen. Heel graag. Maar daar heb je eigenlijk hetzelfde bij, dat een explainable AI of een algoritme uitlegbaar maken is één, maar wat gebeurt er eigenlijk daarna met die uitleg? Ja, wil je daar iets meer over vertellen? Ik bedoel, explainable AI is ook een deel van... Ik wou zeggen, je opent hem aan jongens. Misschien vertel ik eerst nog wat over dat maturity model. Ja, die gaan we ook doen. Ja, die gaan we zeker doen. Misschien is het, want dat is eigenlijk de uitkomst geweest van veel van die sessies. Is dat wij door die sessies, en wat we dus zagen, is dat we hadden oplossingen en verschillende type aanpakken, verschillende type context, we hadden die afwegingen tussen principes, we hadden manieren hoe je dat kan operationaliseren, en we zagen eigenlijk constant dezelfde patronen terugkomen. En dezelfde, we noemen dat organisatorische dimensies, die bijdragen om dat nou op een goede manier aan te pakken. Dus dat zijn we gaan vastleggen. Kijk. En dan zijn we er kijk van, nou oké, als je nou vanuit het organisatorische perspectief ervoor wil zorgen dat je dit op een goede manier, en langzaam naar die volwassenheid ook gaat, zodat je een organisatorische infrastructuur kan creëren, maar door wat er ook op je pad komt, dus wat voor morele dilemma's er waarschijnlijk gaan komen door het implementeren van een algoritme, want vaak weten we dat nog niet. Dat noemen ze ook al het Cogginbridge dilemma. Vroeg in het proces weet je nog niet wat de impact is, en later in het proces weet je wat de impact is, maar kan je er niks meer aan doen. Precies, een oeps moment. Precies. Een leermoment. Kan allebei. Maar we willen die infrastructuur creëren dat wat er ook op je pad komt, dat je daarmee om kan gaan. Opnieuw die processen, praktijken. Dus wij hebben toen zes dimensies geïdentificeerd. Dat gaat heel erg over cultuur en bewustzijn van een organisatie. Het gaat over een stukje beleid. Een stukje governance. Om dat beleid ook te verwerken in structuren en processen. Communicatie en training. Niet alleen maar intern, maar ook buiten de organisatie. Development processes, dus alle development praktijken. Waar moet je alle rekening mee houden. En ook bijvoorbeeld de omgeving waarin je je ontwikkelt en wat voor standaarden je daar rondomheen hebt ontwikkeld als organisatie. Waar moet ik dan aan denken als je het hebt over die standaarden/omgeving? Omgeving bijvoorbeeld ontwikkel je lokaal. Of in een cloud of heb je een bepaalde ontwikkelomgeving. Die heeft ook bepaalde structuren waar je aan moet houden. Of bepaalde manieren om van te werken. Die je meer of minder inzicht kunnen geven in hoe het algoritme werkt. Dus echt die context zo helder mogelijk te krijgen, is dit ook een belangrijk aspect. Ja. En de laatste is een stukje tooling. Dus denk aan meer procedurele tooling. Er zijn bijvoorbeeld heel veel spellen of methodiek ontwikkeld om het gesprek op gang te krijgen. Maar er zijn ook heel veel technische tooling. Fairness metrics, waar we het net ook al over hadden. En er zijn ook meer fundamentele methodiek en framework ontwikkeld. Dus denk bijvoorbeeld aan een IAMA. Dus na elke dimensie, en dat hebben we ook in een artikel opgeschreven, die zes dimensies. Nu zijn we bezig, hoe kun je die dimensies nou weer onderverdelen in sub-dimensies. Dus het wordt nog groter. Ik zal je de sub-dimensies voor nu besparen. Maar op al die dimensies moet je groeien? Ja. Neem ik aan. Dus het idee is dat het een holistische aanpak is. Dat is heel erg belangrijk. Dus waar dit maturity model bij helpt, is een kaart brengen van waar sta je nu eigenlijk. Waar zou je naartoe willen? In de komende jaar, drie jaar, vijf jaar. En wat is dan dat pad dat je zou moeten belopen? Dus in ieder geval hou vast. Dat is ook het leuke en het mooie daaraan. Dat je dus kan zien waar sta je. Wat het ook nog biedt, is dat je ook nog een soort van vergelijking kan gaan doen. Vergelijking is misschien het verkeerde woord, maar je kan eigenlijk identificeren van wie kan je nou eigenlijk leren. Dus die is, een is sterker in het een en de andere sterker in het ander. En ga elkaar opzoeken om van elkaar te kunnen leren. Wat ik heel mooi vind, is dat je kan meten waar je staat. Want ik denk dat dat voor veel bedrijven nog onbekend is. Waar sta ik eigenlijk, voordat ik ergens naartoe wil groeien? Wat ik me afvroeg bij het lezen van het artikel, is hoe bepaal je waar je nu staat? Is dat een vraag? Hoe kom je daar toe? Daar zijn we precies nu mee bezig, want we zijn het model aan het uittesten in de praktijk. Dus dat is voor ons ook een heel leuk leertraject. Dat doen we nu onder andere met onderwijsinstellingen. Dan zie je al dat het bepaald soort type organisaties zijn, waar er weer een andere soort vragen komen. Dus een van de vragen die bijvoorbeeld opkomen is, moet je dat maturity model nou zo generiek mogelijk houden? Of moet je dat misschien wel op de sector of industrie gaan specificeren en bepaalde bewoordingen gebruiken? Of misschien zijn er wel andere dimensies? Dat zijn een van de vragen die nu opkomen. Maar ook, wat is nou de organisatie die je meet? Dus een onderwijsinstelling, bijvoorbeeld bij een universiteit, heb je de universiteit als geheel, maar ook de faculteiten daaronder. En waar meet je dan de volwassenheid van? Dus dat zijn aspecten. Maar ook, hoe vraag je het uit in de organisatie? Is het misschien de nieuwe AI ethics officer of digital ethics officer die dit zelf gaat invullen? Of ga je dat doen met een team? Of zet je dat uit breder in de organisatie? Dus dat zijn precies de dingen die wij nu aan het uittesten zijn. Wat zijn nou de implicaties als je het op manier A of manier B doet? Heb je ze alle drie al geprobeerd? Of ben je er maar bezig? Ja, we hebben ze wel alle drie al gezien. En het ligt er ook heel erg aan wat de status of het momentum is in die organisatie. Want het moment dat je het breder gaat uitvragen, moet je ook andere methodes toepassen om die uitvraag te doen. Dus dan ga je veel meer naar surveys. En daar zitten ook weer implicaties aan. Dus zo kan je eigenlijk door blijven gaan. Ja, gevoelsmatig zou ik gelijk zeggen, dat moet een breder publiek zijn. Want als één iemand het gaat invullen, dan doet hij het vanuit de perspectief van die persoon die is misschien dagelijks op basis daarmee bezig. En die zal automatisch hoger gaan invullen. Want op dagbasis is die bezig met die onderwerpen. Terwijl organisatie breed, waar meestal vaak de challenge ligt, hoe krijgen we die vooruit met elkaar? En dat zou je misschien een heel ander antwoord krijgen als je die vraag stelt. Ja, en ik denk dat het leuke van het model, dat vind ik ook weer de toegevoegde waarde, dat het ook weer die discussie op gang brengt. En dan heb je weer die intrinsieke waarde van ethiek. We hebben ook wel eens een werksessie gehad met meerdere organisaties, waar er meerdere afgevaardigden waren per organisatie, en dat ze samen dat model moesten invullen. Maar ze moesten ook individueel een eigen vragenlijst invullen. En dan zie je dus dat er al verschil tussen zat. En dan krijg je die discussie op gang van, maar waar staan we nou? Ja, precies. Dus eigenlijk ga ik me even tegen spreken inderdaad. Ik denk meerdere keren invullen met de CONS, met een team, voor de afdeling en vervolgens ook met andere afdelingen en als organisatie, met verschillende perspectieven kijken naar waar staan we. Ik denk dat dan echt de conversatie, want daar gaat het wat mij betreft om in zo'n maturity model, is dat je weet welke conversaties moeten we hebben om de beweging te gaan waar we heen willen. Ja, precies. Dat is precies hetgeen wat denk ik mogelijk gemaakt wordt door... Het is eigenlijk een tool in je gereedschapskist. En hetzelfde met... Dat zie je natuurlijk ook vaker. We hadden het net over die ethische afwegingen. Organisaties ontwikkelen nu bepaalde boards of committees. Het gaat er niet om dat het één keer wordt bekeken, maar het gaat erom dat het continu onderdeel blijft van het gesprek, zeker als het algoritme ook constant gebruikt wordt. Ja, wat in principe de bedoeling is. Toch? - Precies. Dat hopen we wel. Nog een vraag die bij mij opkomt is dan... Je hebt het één keer gemeten. Dat hebben we met een bepaalde groep gedaan. Maar wat je zelf ook net al aangeeft, dat wil je vaker gaan doen. Kijk je ook naar van hoe ga je dat repeatable doen? Ga je dan elke keer dezelfde groep uitnodigingen? Hoe ga je daarmee om te kijken of je die voortgang hebt gemaakt die je wil maken? Ja, dus we gaan nu een pilot met die onderwijsinstellingen doen. Dat zijn precies de vragen die we daar ook onszelf gaan stellen. En niet om... De tool is nooit de oplossing. Maar je wil misschien wel het ergens kunnen borgen. Dat kwam je net ook al aan. Je wil het ergens vastleggen en niet dat het ergens verdwijnt in een folder. En dat is het. Dus daarvoor zijn ook die mutual learning sessies die wij organiseren met verschillende typen organisaties. Kan je ook natuurlijk intern organiseren. Misschien juist ook. Want dat is makkelijk herhaalbaar. Precies. Elke derde donderdag van... Ja, inderdaad. Dus dat is ook zeker iets wat je intern kan doen. En zo'n maturity model helpt daar alleen maar mee. Is het maturity model open? Kunnen we het ergens vinden? Lezen? Zullen we opnemen in de show notes? Kan iedereen dat gaan lezen? Dat is een aanrader inderdaad. De aanrader van mij is gelijk die tabel. Met al die verschillende stappen erin. En de volwassenheidsniveaus inderdaad. Zou je een aantal volwassenheidsniveaus kunnen noemen? We hebben net dementies gehad. Ja, dus we hebben vijf volwassenheidsniveaus geïdentificeerd. In ieder geval gebruikt in onze eerste mapping. En level 1 gaat eigenlijk over het feit dat er eerst... Nou ja, er is eigenlijk nog niet heel veel. Maar je ziet, daar doen we het misschien te kort mee, om te zeggen, er is nog niet zo veel. Want vaak zijn er wel individuen of bepaalde teams in de organisatie die er wel over aan het nadenken zijn. Maar het is niet iets wat structureel breed gedragen wordt. Maar het is afhankelijk. Dus stel je voor, die persoon zou de organisatie verlaten. Dan is ook de aandacht voor dat onderwerp weg. Ja, precies. Dus dat is voor ons op niveau 1, of nog helemaal niks. Er wordt nog helemaal niet aan gedacht. Dus op al die dimensies kan je dat eigenlijk gaan evalueren. Level 2 gaat veel meer over dat er juist initiatieven worden opgestart. Vaak op teamniveau. Of er wordt een eerste projectgroep gestart. Of een werkgroep van, we moeten iets mee doen. We gaan nu iets opzetten. Maar dat kan ook een groepje data scientists zijn die denken van, we willen eens gaan duiken in die technische methodes. Hoe kunnen we dit nou optimaliseren? En dan zie je eigenlijk op level 3 dat je dat steeds meer gaat van het informele naar het formele gaat brengen. Dus je gaat het vastleggen in bepaalde checks, procedures, manieren. Het wordt meer regulier. Dat je het terug laat komen. Het wordt meer structureel. En in level 4 bal je dat eigenlijk uit. En dan gaat het ook om dat je wilt die integratie in de organisatie. Dus waar bij level 3 misschien nog iets meer ad hoc is, wordt het bij 4 al echt iets ingebouwd in bestaande processen. Dus processen, functieprofielen, staat het misschien omschreven. Dat het onderdeel van je werk is. Dat je er trainingen voor moet volgen. Precies, dus op het moment dat je ergens gaat werken. Als je onboarding, zit het al verwerkt. De ontwikkelomgeving is vrij robuust opgezet. En die zorgt er ook voor dat je die ethische aspecten kan involveren. Het beleid is volledig uitgewerkt, maar ook volledig geïmplementeerd. Want dat is ook nog wel iets dat we vaak zien dat er wel beleid is. Dan zie je toch meer rond level 2, 3. Maar het is nog niet volledig geïmplementeerd of het leeft nog niet binnen de organisatie. Dat is een van de sub-dimensies bij beleid. Dat je beleid evalueert. En dat je kijkt, komt het nou nog overeen met de standaarden en de wetgeving die zich ook ontwikkelt. Dus dat is ook een stukje monitoring dat daarin zit. En richting level 5 ga je echt veel meer richting monitoren, evalueren. Zorgen dat je up to date blijft. Het is niet zo van ik ben bij level 5 en dan ben ik klaar. Helaas. Dan begint het eigenlijk per zegt. En ethische normen en waarden verschuiven natuurlijk ook. Ja, dat is iets heel belangrijks. En dat maakt ethiek ook super ingewikkeld. Dat het gebruik van de technologie verandert onze normen en waarden ook weer. Soms kan je ook niet bepaalde ethische aspecten vangen in formules, definities. Omdat het juist constant verschuift en ook verschilt per groep, perspectief, wat het dan betekent. Je hebt het per definitie, tenminste in mijn definitie, per definitie over een grijs gebied. Ja. Het is heel moeilijk sowieso af te kaderen. Dus je bent het op een gegeven moment ergens met elkaar eens ofzo. Maar er is geen hele harde scheidslijn die zegt van ja, als we hier zijn is het fout en als we daar zijn is het goed. Ja, en daarom is die continue reflectie zo belangrijk. Omdat je dus niet weet wanneer het gaat veranderen en hoe het gaat veranderen. En daar zijn natuurlijk heel veel voorbeelden van gewoon in een bredere zin van technologie en de ethiek van technologie. Is dat je bijvoorbeeld, nu vinden we het heel normaal dat iedereen op straat loopt met zijn airpods in. En dat iedereen tegen zichzelf aan het praten is. Ja, precies. Terwijl dat iets, als je dat tijdens je geleden had, dan denk je van, nou wat raar. Dat je dat 20 jaar geleden had gedaan ofzo. Ik heb dat nog hoor. Ik moet zeggen, ik doe dat best veel. Ja, nee ja. Ja, en dan zijn er nog steeds heel veel mensen die dat ook raar vinden. Ja, en dat soort dingen gaan langzaam. Ja, wordt anders zeker. En daar wordt vaak ook gekeken naar de harde impact van de kwantificeerbare en de impact van algoritmes en AI. Maar er zitten heel veel zachte kanten aan. Verantwoordelijkheden, waarden, frameworks, dat soort voorbeelden eigenlijk aangeven. En bij ethiek hebben we best wel heel vaak te maken met dat er heel duidelijke voorbeelden zijn hoe het niet moet. Maar uiteindelijk leren we het meeste van hoe het wel moet. Heb je daar een voorbeeld van? Ik voelde er wel aan komen. Ja, de niet voorbeelden zijn altijd heel makkelijk aanwijsbaar. Heb je iets van een voorbeeld, en dat mag wat in het algemene zijn, van dat je zegt van, ja maar hier is dat best wel heel goed gegaan. Als je deze stap al maakt, dan maak je in die zin al een reuzenstap. Ik denk dat, misschien een heel makkelijk antwoord, maar tijd. Dat zie ik terug in mijn eigen onderzoek, maar ook wel in andere aspecten. Daar moet ook tijd voor zijn om hierover na te kunnen denken. En dat wordt op verschillende manieren vormgegeven. Wat steeds meer gebeurt is dat er bepaalde rollen ontstaan. Dus AI ethics officers, AI ethics specialists. Dat is eigenlijk een vorm van, wij geven hier nu aandacht aan. Dat is één manier, maar het kan natuurlijk ook zo zijn dat andere rollen tijd krijgen om hier aan te werken. O ja, dat is een goede. Dus je kan een waarde framework ontwikkelen. Maar er moet ook wel tijd zijn om hem te implementeren. En hem toe te passen op jouw context. Dus ik denk dat één van de dingen die ik veel terug zie en waarvan ik denk dat is wel een goede stap. En dat zit ook wel in dat maturity model verwerkt. Maar er zijn heel veel principes en frameworks beschikbaar. Maar vertaal die naar je eigen context. Want de context van jouw organisatie is zo specifiek. Er zitten zoveel unieke aspecten aan. Die zijn niet te vangen in die abstracte principes die je op alle contexten kunt toepassen. Dat is altijd wel weer lastig, want mensen zijn natuurlijk altijd weer op zoek naar een recept. Ik neem aan dat dat best wel lastig is. Ja, maar dat is denk ik ook, want je vroeg van heb je een voorbeeld. Ik denk als dat lukt, dat dat al stap 1 is. Ja, dat vind ik wel een hele mooie. Het kan zijn dat het wel overeenkomt met die algemene principes. Maar het kan zijn dat de nuance in jouw context toch net iets anders ligt. En een ander best practice is dat je kan het per principe aanpakken. Dus je kan zeggen, we gaan nu bezig zijn met bijvoorbeeld uitlegbaarheid of fairness. Maar vaak zit er toch een bepaalde overlap in met andere principes. Dus ik zou juist vanuit die organisatorische blik gaan kijken en niet vanuit die principeblik. Want vaak, om fairness aan te pakken, moet een algoritme ook wel vaak explainable zijn. En dan wil je ook weten wie daar verantwoordelijk voor is om daar weer iets over te zeggen. Ja, dat vind ik wel een mooi uitgangspunt. Een hele holistische aanpak. En hoe weet je nou dat je, want dan ga je hier mee bezig. Ik noemde al van het is een grijs gebied. Hoe weet je nou dat je hier impact op maakt? Wat is impact? Sorry. Dat is een hele goede tegenvraag. Nou ja, dat je verschil aan het maken bent. Dus dat wat je aan het doen bent... Dat je verandering ziet bedoel je? Dat je verandering ziet, ja. Ja, ik denk dat op het moment dat je wilt een cultuur of een setting creëren waar mensen kunnen signaleren van... "Hé, ik weet het niet. Ik weet niet zeker of ik dit mag gebruiken of dat we dit wel moeten doen." Dus dat is heel erg iets interns, denk ik. Want je kan soms ook als je één rol hebt die alles implementeert, die kan niet alles overzien. Als je ervoor wilt zorgen dat iedereen die verantwoordelijkheid begint te voelen. Ja, precies. Dus als het gesprek breder in de organisatie een punt wordt... Ik probeer hem te vertalen, zodat ik me zeg of ik het goed heb. Dus als het iets is wat eigenlijk tijdens de lunch besproken wordt... "Niels, ik dacht dat jij dit ethische aspect nog wat verder zou uitzoeken, maar dat heb je niet gedaan." En dat je elkaar er misschien ook op aanspreekt. Dat je dan impact maakt. Dat er een verandering plaatsvindt. Ja, dus dat is intern. Ja, ik denk dat... Dat jij dat organisatorische deel... Ja, en dan heb je misschien weer meer over dat interesse. Maar je hoopt uiteindelijk dat het toe ook leidt dat er bepaalde keuzes gemaakt worden. Zodat je niet... Misschien die unintended... Ja. Dat hetgeen wat je misschien niet had voorzien, dat dat steeds meer geïdentificeerd kan worden. En in ieder geval van tevoren over nagedacht van "Wat zou er kunnen gebeuren op het moment dat we dit doen?" Ja. Dus dat we ideeën vanuit een breder perspectief gaan bekijken. Los van jouw deel van expertise, maar ook al verder gaat kijken. Zonder dat daar eerst een hele setting voor gecreëerd moet worden. Maar dat iemand zelf opstapt als dat er nog niet is. Om daarmee aan de slag te gaan. Bijvoorbeeld, ja. En natuurlijk ook in een bredere zin impact. Je wilt uiteindelijk ook dat de burgers, jouw klanten, de maatschappij in het algemeen... Ik denk dat het heel belangrijk is, en dat zie je nu ook met generatieve AI, dat bepaalde bestaande biases en bepaalde systematische problemen die er al zijn, dat die niet nog verder versterkt worden. Ja. En daar zitten elke keer als we iets meten, of het moment dat wij een keuze moeten maken, een bepaalde threshold moeten zetten, maken we al een bepaalde keuze, dat is een menselijke keuze, hoe iets eruit moet komen te zien. Hoe kijk je dan, misschien gaan we er een heel klein zijstapje in doen, hoe kijk je er dan tegenaan, zeg maar, hoe op dit moment Big Tech daarmee bezig is, want die data die ze gebruiken, daarvan weten we één ding zeker, die is heel erg biased. Ik zag zelfs, ik dacht dat het OpenAI was, ik weet even niet helemaal zeker, OpenAI die licentie nu had afgesloten met Reddit, waarvan we weten dat, Reddit is zo'n open riool forum, laat ik het maar even zo noemen, in ieder geval delen daarvan, en dat gaan ze dus gebruiken in hun generatieve AI, dus zij zijn eigenlijk nog meer bias in hun modellen aan het stoppen. Ja, en ook weer niet, want je zag bijvoorbeeld Google Gemini, zag je dat ze diversiteit probeerden toe te voegen aan hun model, en dat ging er juist de andere kant op. En er is een heel mooi artikel die eigenlijk verschillende traps, dus valkuilen, aangeeft, van wat gebeurt er nou als je dus met biased data aan de slag gaat, en ook vooral kijk naar hoe kunnen we dat algoritme nou, want ik denk dat dat een van de dingen was die we bij Google Gemini, ze hebben het algoritme aangepast om die diversiteit, of ik was er niet bij, maar... Nou ja, het probleem is, Google die dag zich, er is een aparte aflevering van, maar die dachten zich er makkelijk van af te maken, door namelijk de prompt die je dan opgeeft, gewoon even als dat over mensen gaat, er achteraf toevoegen van, maak er een diverse groep van. Dat heeft niets te maken met het algoritme aanpassen, maar gewoon eventjes je prompt. Ja, dat was grote stappen snel thuis, maar dat... Ze waren weer zo snel thuis. Ze waren heel snel thuis, ja. Het is even offline gegaan zelfs, hè. Dus ze hebben in ieder geval de pijn gevoeld. Ja, dus ik denk dat, er zijn dus verschillende valkuilen, dus bijvoorbeeld een van die valkuilen ook is dat, technologie of de tool is niet altijd de oplossing. Dus dat, in dit geval een prompt is niet de oplossing. Precies. Omdat soms is dat gewoon, iets zoals diversiteit of fairness, is gewoon zo moeilijk te vangen. Wordt nog steeds over, er zijn heel veel debates, contests. Ik denk dat het eigenlijk wel een heel mooi voorbeeld is van alles wat jij verteld hebt, want wat er natuurlijk bij Google gebeurde, is dat zij... Ze hadden eerst, Lambda heette dat model nog, dan kreeg je die Google Test Engineer, en die vond dat dat model zelfbewustzijn had en zo. Dat is een hele hoop gedoe geweest, man ontslagen, model teruggetrokken. Maar wat zij vooral toen gedaan hebben, is hun ethics team hebben zij volledig uitgekleed. En nu dus een jaar, anderhalf jaar later, zitten we er dus met Gemini. En wat hebben ze gezien? We hebben misschien een ethisch probleempje. Mensen zien het niet hoor, tussen aanhalingstekens, probleempje. En daar dachten een paar technici, oh, maar daar past er gewoon even een promptje aan. Volgens mij heb je het daarover gehad toch? Het zit niet in de organisatie, het is niet geëmbed, het wordt niet gevoeld. En er is iemand waarschijnlijk geweest die dacht van, oh ja, maar hier moeten we wel wat mee. En dus op de slechts mogelijke manier is dat vertaald. En ook die andere punt die je net noemde, eigenlijk tijd. Tijd, focus en prioriteit. Tijd maken en focus op aanbrengen en prioriteit geven en niet te snel willen gaan. Volgens mij zitten we ook in een maatschappij waar alles heel snel gaat. Ja, ik denk dat dat wel een hele belangrijke is inderdaad. Dat echt even de tijd voor pakken en niet te snel willen gaan inderdaad. En niet de red race per se willen winnen, maar het goed willen doen. Ja, en dat ook. Als je water hebt en water is het sociale systeem waarin, en dan heb je een druppel wat de technologie is die je erin, dan heb je een bepaald effect. Ja, dat rimpel effect. En door één klein dingetje aan te passen, kan er eigenlijk een effect ontstaan en die kan ook heel anders zijn in verschillende contexten. Nu was het inderdaad met foto's, maar in een ander context was misschien de implicatie heel anders geweest en waren ze misschien beter uitgepakt. Je weet het niet. Of subtieler, waardoor je het minder snel detecteert. Kijk, nu was het zo, zo zichtbaar. Dat was in ieder geval nog het voordeel. Het gaat juist om die subtiele... Ja, en zeker als daar nog een menselijk besluitvormingsproces tussen zit, dat het advies aan de mens wordt gegeven, daar zitten daar ook weer allemaal aspecten aan. Bijvoorbeeld iemand zijn eigen perceptie, iemand zijn rol in de expertise verandert. Of bijvoorbeeld, het kan zijn dat de ene persoon denkt, ik ga dit gewoon opvolgen, en de andere persoon negeert het. Dus daar ook weer de implicaties van en bepaalde machtsverhoudingen. Die worden ook allemaal beïnvloed. Snap ik. We hebben ook Aisha, onze virtuele co-host. En die zou je ook graag even willen aansluiten. [muziek] Het is een genoegen je te ontmoeten. Ik ben Aisha, de AI hier. Ik zou graag een vraag willen stellen, als je het niet erg vindt. Ja, dat mag. Natuurlijk. Welke science-fiction film geeft volgens jou de toekomst van AI nauwkeurig weer? Interessante vraag. Nauwkeurig weer, dat is wel heel erg interessant. Nauwkeurig vooral. [lachen] Ik moet eerlijk toegeven, Aisha, dat ik niet een hele grote filmfan ben. Ik hou wel erg van lezen. Oh, dat is ook mooi. Ik weet niet echt of het de toekomst vergeeft, maar een boek wat mij zeker toen ik philosophie studeerde heel erg aan het denken zat, was I, Robot van Isaac Asimov. Toen kwam die ook met drie regels, hoe robots mensen... En daar zijn ook weer heel veel reflexen op geweest. Ik denk dat de kracht van verhalen en de kracht van bepaalde dingen laten zien ook juist weer die discussie op gang kan brengen. Eigenlijk je eigen reflectie van wat gebeurt er nou eigenlijk op het moment dat zo'n technologie beschikbaar is. En ik denk ook dat... Hij heeft acht verhalen in dat boek. Een film kunnen natuurlijk ook meerdere verhaallijnen zijn. Maar die acht verhalen laten ook weer verschillende aspecten van onze samenleving zien. Dus wat als je bevriend wordt met een robot of wat als we een robot inzetten in een militaire contact. Dus ik vind dat soort verhalen altijd heel erg... Zorgen er bij mij voor dat ik weer ga reflecteren op wat nou de impact kan zijn. Bedankt voor dat heldere en informatieve antwoord. Ja, zeker interessant. In mijn beleving is er geen film die het nauwkeurig weergeeft. Want we houden natuurlijk van lekker dystopisch. Het gaat altijd mis. Wel weer gesprekstof inderdaad. Willen we die kant niet op laten gaan. Ik denk als we die films niet hadden, hadden we die gesprekken misschien niet gehad en dan had het er geweest. Geen idee. Ik weet wel dat in Rotterdam een kino een serie hebben gehad met allemaal films over AI en science fiction. Dus mocht je nog een hele lijst met films over AI willen zien, dan wil ik dat je daar naartoe kan. Ook bekend als Her. Natuurlijk met online datingachtige context. Maar ook iRobot zelf. Ik moest gelijk aan de film denken. Ik ben minder van de boeken lezen maar meer van de webcast en dat soort zaken. I, Robot is natuurlijk ook een film waarin ook de drie wetten zijn opgenomen. Zo zijn er nog wel aardig wat andere films. Maar nauwkeurig, nee. Om dat toch wel even duidelijk te zeggen. Maar het is wel interessant als je denkt aan de film Her. Wat daar zich afspeelt met de ontwikkelingen die er de afgelopen jaren zijn geweest. Hoe meer dat eigenlijk werkelijkheid is geworden. En je dat op verschillende manieren terug ziet in verschillende technologieën. Niet exact zo, maar in een ander context. Dat is een hele mooie. Nog als laatste over het maturity model. Mensen hebben dit geluisterd. Wat is de eerste stap wat ze gaan doen? Dus ze zetten zo direct deze podcast uit. Wat gaan ze in jouw beleving doen nu met deze informatie? Als je wilt kan je het artikel lezen. Ik wil niemand verplichten om het hele artikel te lezen. Maar ik denk dat het wel erg helpt om te begrijpen. Wat is nou de context geweest en hoe we het hebben ontwikkeld. En wat betekent het nou? En de eerste stap die je al kan zetten. Het staat een tabel in en er staat ook een raamwerk in. Is gewoon eens opschrijven wat is er nou eigenlijk in mijn organisatie. Het maakt niet uit wat voor rol je hebt. Je hoeft niet per se degene te zijn die hiervoor verantwoordelijk is. Maar ga nou eens opschrijven wat je al hebt. En waar zou je graag willen staan. En dat al eens een keer bespreken. Ga dat dan een keer met een collega bespreken. En kijken of die daar dezelfde percepties bij heeft. Dat kan je eigenlijk steeds verder uitbouwen. Dan kan je op een gegeven moment gaan kijken van oké, maar hoe komen we daar nou? En wat zouden we dan nu moeten doen? En dan zou je kunnen kijken van, nou ja, als je die mapping al neerzet. Kan je al kijken van welke dimensies ben ik nou al wat volwassener in. En waar heb ik eigenlijk nog helemaal niet aan gedacht. Nou dat lijkt me een hele mooie. We zijn niet toegekomen aan de explainability. Daar moeten we nog eens een ander moment voor kiezen. Maar ik ben bang dat als ik daar nu over begin. Dat we de volgende drie kwartier bezig zijn. Tamara, super bedankt dat je hier wilde zijn. Dat je dat maturity model, dat je dat hebt willen uitleggen aan ons. Heel erg interessant. Heeft mij ook weer aan het denken gezet. Ik denk dat Niels en ik ook maar eens weer moeten gaan beginnen met schrijven. Ja, zeker. Dus wij gaan in ieder geval wel die eerste stap uitvoeren. Dank je wel dat je hier wilde zijn. Dank je wel voor de uitnodiging. Leuk om hier te zijn. Leuk dat je luisterde naar deze aflevering. Vergeet je niet te abonneren via je favoriete podcast app. Dan krijg je vanzelf een seintje als er weer een nieuwe aflevering beschikbaar is. Op de maandag altijd met een gast. Op de donderdag een korte column. Tot de volgende keer. Tot de volgende keer. 