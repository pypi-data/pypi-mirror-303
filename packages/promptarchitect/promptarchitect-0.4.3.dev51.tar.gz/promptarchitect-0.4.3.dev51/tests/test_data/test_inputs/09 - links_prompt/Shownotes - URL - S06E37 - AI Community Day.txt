Hoi, leuk dat je weer luistert naar een nieuwe aflevering van AIToday Live. Mijn naam Joop Snijder, CTO bij Aigency. Mijn naam Niels Naglé, Area Lead, Data & AI bij Info Support. En we hebben vandaag een hele leuke aflevering. We gaan het namelijk hebben over communities en wel te verstaan AI communities. En daarvoor hebben we Henk Boelman in de studio. Henk, hartstikke leuk dat je naar onze studio wilde komen. Zou je je eerst willen voorstellen aan onze luisteraars? Ja, hallo allemaal. Mijn naam is Henk Boelman. Ik ben Senior Cloud Advocate bij Microsoft. En in mijn vrije tijd en gedurende mijn werk natuurlijk heel erg veel bezig met community en vooral AI community. Dus dankjewel dat ik hier mag zijn vandaag. Ja, en dat doe je eigenlijk al lang, want er is een soort van voor en na ChatGPT. Dus we zijn zeg maar na november, hebben we, laten we zeggen de community is heel veel groter geworden. Maar jij zat al in de community ruim voor dat gebeuren. Ja, ik ben in 2017 begonnen met de AI community. Met de Global AI community, met de welbekende van jullie, Willem Meints. En eigenlijk ons idee daar was, omdat er toen nog zo weinig beschikbare content was voor mensen om te verspreiden binnen communities. Om dat eigenlijk makkelijker te maken. Dus centraal content neerzetten, centraal presentaties neerzetten. En andere mensen te helpen om dat te geven en te presenteren in hun communities. En dat is eigenlijk het idee waarmee de global AI community in 2017 begonnen is. En global was daadwerkelijk global, he? Het was echt de wereld rond. Het was inderdaad de wereld rond. Iedereen op een vaste dag kon een evenement organiseren met de content die wij dan beschikbaar stelden. En dat deden toen zo'n 50, 60 locaties rond de wereld. En daar kwamen echt veel mensen op af. En de allereerste, die hebben we samen gedaan toen nog met een andere technologie, Mixed Reality. Dus we hadden de global Mixed Reality bootcamp samen met de global AI bootcamp. Cool. Ja. En die community, dat groeit. Waar richt je je nu vooral eigenlijk op? Eigenlijk is het concept nog niet zo heel veel veranderd. We zijn nog steeds bezig om met de Global AI community, om andere communities de kans en de mogelijkheden te geven om evenementen te organiseren. Door middel van het platform wat we bieden met de Global AI community, met Meetup Pro en content. En dat ze hun evenementen daar kunnen registreren. We zijn wel wat uitgebreider met content nu. We hebben nu ook workshops, heel veel presentaties over allemaal verschillende onderwerpen. Maar wat we eigenlijk voornamelijk nu zien is dat de doelgroep veel groter geworden is voor deze community event. Eerst was het veel meer op de data science gericht. Er is machine learning bijvoorbeeld. Hoe train je nou zelf je modellen? En we zien nu dat eigenlijk de interesse verschuift naar eigenlijk elke developer. Die wil leren hoe die dat kan gebruiken in de applicaties die ze maken. Ja, want er gaat natuurlijk een hoop veranderen. Niet alleen in de applicaties die je maakt, maar ook hoe je zelf met software omgaat. Dus hoe je software ontwikkelt. Is dat ook een onderwerp daarvan? Ja, ik denk dat je nu de codepart is bedoeld die je helpt om code te genereren, code makkelijk te maken. En dat is natuurlijk wel een hele shift. Ik maak zelf ook heel veel demos. En ik merk ook zelf dat ik het steeds meer ga gebruiken. En steeds minder naar mijn browser ga om snippets op te zoeken. Maar dat ik een soort van leer om met mijn developer-IDA nou te praten. Zo van, hé, ik wil dit bereiken. Hoe doe ik dat? En dan, nou ja, dat is goede code. Dat had ik zelf niet bedacht. Het is wel grappig dat je dat zegt, hè. Dat je na gaat denken over je doel. Terwijl misschien eerst bij het programmeren was je misschien wat taakgerichter. Je denkt van, ik moet dit doen, ik moet dat doen, ik moet dat doen. En dan programmeer ik uit. En nu heb je een doel voor ogen en dat beschrijf je. Waardoor het programmeren makkelijker wordt. Ja, absoluut. Je zit niet meer te denken van, welk if statement of welke reguliere expressie heb ik hier nu voor deze lijncode nodig? En dat ga je opzoeken. Maar inderdaad van, ik wil links actief maken in mijn chatgesprek. Schrijf maar. Denk je dat het daardoor ook toegankelijker wordt voor mensen om te gaan programmeren? Ik denk dat het antwoord op is ja. Ik denk het wel. Ik denk wel dat we nog steeds ontwikkelaars nodig hebben die moeten kunnen controleren of de code daadwerkelijk doet wat het moet doen. Want ik krijg soms ook suggesties die zijn gewoon fout. Dat is niet hoe je programmeert. Ik denk dat we heel erg moeten oppassen in hoe we applicaties neer gaan zetten. Het framework bouwen voor die applicaties net zoals dat we MVC hebben en hoe we dat op een goede manier implementeren. Ik kan niet mijn Co-pilot vragen schrijf eventjes zo'n structuur of hou die structuur nog in de gaten. Dus de taak van de developer verschuift. Zie je dat ook terug in de content van die AI Community dagen dat die dat nu meer gaan bevatten en dat er dus daardoor ook ander publiek opkomt? En wat ik vooral zie is dat een shift in de sessies, vooral nu met de opkomende AI Community Day, is dat we veel meer sessies zien over hoe je daadwerkelijk iets bouwt in de echte wereld. Terwijl het een jaar geleden allemaal was dit is hoe je de API aanroept. Dit is wat je ermee kan en dit is hoe je het installeert. Dus ik vind dat persoonlijk heel erg leuk want daarvan leer je echt hoe mensen het zelf hebben toegepast. We hebben het erover, hij komt eraan. We hebben volgens mij nog niet genoemd wanneer hij eraan komt. Want het is korte termijn, want je hebt het nu over sessies die ingediend zijn, die denk ik bekeken worden. Dus hij is ook binnenkort? Hij is binnenkort, hij is op 14 mei. Dat is inderdaad net na de vakantie. 14 mei Utrecht hè? Ja, in de fabriek in Utrecht. Prachtige oude fabriekslocatie, altijd lekker eten. Drie tot vier zalen zijn er waar mensen naar verschillende soorten sessies kunnen. En kan je nog even aangeven hoe mensen zich kunnen aanmelden, wat de tijden zijn? Even gewoon heel praktisch. Zodra mensen, nadat jij dit vertelt, even op de pauzeknop drukken en zeggen van ik meld me even aan voor de AI Community Day. Daarna gaan we weer verder. Helemaal goed. De AI Community Day is op 14 mei van 3 tot 9 uur 's avonds. Er zijn twee sessies voor het eten, na het eten is er een keynote en dan zijn er nog twee sessies. En dan is er natuurlijk nog de gelegenheid om nog even te blijven hangen om nog wat te drinken. Het is in een fabriek in Utrecht, makkelijk bereikbaar met het OV. Zeker als het zo'n lekker weer is als vandaag. Is het een prima stukje lopen met het openbaar vervoer, maar er gaat ook een pendelbusje op en neer vanaf het station. En er zijn 900 parkeerplekken. Dus er is ruimte genoeg voor iedereen. Ruimte zat. En de doelgroep? Wie is de doelgroep? De doelgroep is eigenlijk heel erg divers. Ik zeg altijd, het is voor iedereen die wat wil leren over AI. Sommige talks zijn waarschijnlijk te technisch voor sommige mensen. Voor sommige mensen niet technisch genoeg. Dus ik denk dat er voor iedereen, iedereen wat is. En wat ik altijd fijn vind van zo'n community dag is dat er ook altijd tijd is om te praten met mensen. We hebben 15 communities uitgenodigd. En die zijn er ook met een banner, met de communityleden, met de organizers van de meetups. Dus daarmee kunnen mensen kennis maken om verder te leren bijvoorbeeld. Maar ook om in discussie te gaan met elkaar over wat doe jij met AI? Wat heb jij gebouwd? Waarom ben jij hier? Waar werk jij? Bij welke community ben jij hier gekomen? Wat werkt wel? Wat werkt niet? Vooral ook wat werkt niet? In deze tak van sport is dat ook heel belangrijk om te weten. En dan de vraag, hoe kom je daar? Hoe kan je je aanmelden? Op ai.communityday.nl Kijk, die zullen we opnemen in de show notes. En wat kost het? Helemaal niks. Kijk, dus er is geen reden om niet te komen. En leuke content, lekker eten, mooie locatie en je steekt er ook nog wat van op. Ja, wat wil je nog meer? Toch? Klinkt hartstikke goed. Nou, wat wil je nog meer? Wij staan er ook, toch? Ja, zeker. Dus wij geven een sessie over hoe generatieve AI ons helpt bij twee wekelijks, nee ik zeg het verkeerd, om iedere week twee afleveringen de deur uit te krijgen. Daar gebruiken we heel veel generatieve AI ook voor. Leuk. Ik ben natuurlijk heel benieuwd naar die sessie. Want ik heb ook een applicatie gebouwd die dat doet. Dus ik ben heel benieuwd naar hoe jullie dat doen. Kunnen jullie er wat over vertellen? Jazeker, zeker. Nou, een van de dingen, dat ga je straks merken, we hebben bijvoorbeeld een virtuele co-host, Aisha. En Aisha hebben we onder andere gecreëerd met generatieve AI. Dus voor een deel, Aisha is, een profiel is eerst geschreven. Van hoe zouden we Aisha zien? Dus we hebben gezegd, Aisha is uiteraard een vrouw, heeft een bepaalde achtergrond hebben meegegeven, waar ze vooral in geïnteresseerd is. Daar hebben we een profiel laten genereren met ChatGPT uiteraard. En vervolgens ook gezegd, geef nou eens echt een hele lijst van vragen, die interessant zouden kunnen zijn voor de podcast, die wij typisch, zeg maar, als de twee mannen die hier zitten, niet zouden stellen. We hebben een hele lijst van vragen gekregen. En vervolgens hebben we die vragen ook omgezet naar spraak uiteraard. Dus mensen moeten dingen luisteren. Dus je krijgt straks ook spraak te horen. Dus dat is met generatieve AI bijvoorbeeld opgezet. We hebben ook gekozen voor een robotstem. Je hebt natuurlijk nu hele mooie, goede stemmen. Deze podcast, hè. Ik denk wel dat ik Niels vervang of zo. Dat kan. Iedereen is vervangbaar. Of dat ik vervangen word met mijn stemmen. Dus we hebben gezegd, we willen dat het ook heel transparant is. Dat het een vraag is die gegenereerd met een gegenereerde stem. Dus dat is een van de dingen. En de postproductie, dat is eigenlijk het allermeeste werk. Daar hebben we namelijk ook heel veel generatieve AI in gezet. Waaronder bijvoorbeeld de transcripties. Dus we praten zo direct, ik weet nog niet hoe lang, 35, 45 minuten. Als je dat zou moeten uittypen, dan word je daar niet vrolijk van. Dus uiteraard gebruiken we daar ook generatieve AI voor. Maar ook om daar dan weer informatie uit te halen. Dus wat zou de interessante quotes van jou zijn? Wat zouden we kunnen gebruiken in onze LinkedIn berichten? Waar wordt gesproken over wat we in de show notes gaan zetten? Want als ik 35 tot 45 minuten moet terugluisteren, moet ik naar mezelf luisteren wat ik niet fijn vind? Nou, dat stuk kan ik dan nog doen, maar ik ga niet naar mezelf luisteren. Dus dat wordt wat lastig. Dus zo pikken we er ook uit, waar worden interessante dingen genoemd die dan ook daadwerkelijk in de show notes komen. En zo hebben we nog een heel set aan andere activiteiten. Maar daar vertellen we tijdens de sessie natuurlijk veel meer over. Wordt het meer het technische, toch? Met welke modellen je dan hebt gebruikt? Of meer van dit is nu mogelijk? Ik was van plan om daar van alles, eigenlijk een beetje. Dus waarom bijvoorbeeld zetten we wel of geen generatieve AI in? Dus hebben we ook echt keuzes in gemaakt. Dus ethisch vraagstukken komen aan bod. Wat ik net al zei, bijvoorbeeld dat het ook transparant is dat Aisha niet een mens is die een vraag stelt. En ik vertel ook in het uit welke tools, welke modellen. En bijvoorbeeld ook hoe we dat testen. Hoe we ook zorgen dat ook de prompts blijven werken. Heel gaaf. Nou, ik ben benieuwd. Ga je zelf nog een praatje houden? Nee, eigenlijk doe ik geen praatjes op events die ik zelf organiseer. Ja, snap ik. Nee, we hebben een hele leuke keynote van Gabriella. Die werkt bij Microsoft over Small Language Models en over Green AI. Geweldig. Dus ik ben heel benieuwd. En zij werkt ook dagelijks met allemaal klanten die dat toepassen. Zij heeft een hele berg ervaring en een hele berg verhalen om te delen. Dus ik ben heel erg benieuwd naar. Mooi onderwerp. Zeker. Kan je iets, ik weet niet of je daar antwoord op kan geven, over die Small Language Models. Want als je dit nu luistert, een paar dagen daarvoor heb ik namelijk iets verteld over Small Language Models. Wat is jouw blik daarop? Zou je eerst kunnen uitleggen, wat is het? Ik moet eerlijk zeggen dat ik weinig ervaring heb met Small Language Models. Maar, zover ik begrepen heb, zijn dat, geen Large Language Models, maar Small Language Models die op veel minder hardware zouden kunnen draaien. Waardoor ze veel minder energie verbruiken en je ze ook, als het ware, zelf kan hosten. Waardoor je niet naar de clouds hoeft enzovoort. Dus je duration wordt een stuk minder. Want de modellen staan dichterbij. Ja, duration is eigenlijk de vertraging tussen je antwoord en, of tenminste de vraag die je stelt en het antwoord dat je krijgt. Ja, absoluut. En de belofte is dat ze in de buurt komen van de kwaliteiten van de Large Language Models. Ik heb het voor de rest nog niet kunnen testen. Er zijn natuurlijk net weer een aantal nieuwe uitgekomen en beschikbaar in het SJRI Studio. Maar ja, je kan ze dus ook lokaal draaien, wat wel weer heel gaaf is. Ik doe dat bijvoorbeeld zelf met Whisper voor mijn transcripties, voor mijn video's die ik maak. Dat is toch wel gaaf, dat het allemaal op je eigen machine draait. En je hoeft niet al je audio te streamen of te uploaden, maar dat het gewoon in je notebook op je laptop kan draaien. Maar ook handig voor je cost control en dat soort zaken, wat ook meer binnen handen bereik komt op deze manier. Wat als mensen nou zouden willen beginnen, dus we hebben best wel een heel breed publiek aan luisteraars. Als mensen nou willen beginnen en onderdeel zouden willen worden van een community om te gaan leren, om je beter in te worden. Wat zouden jouw tips daarin zijn? Dat is een hele goede vraag. Ik persoonlijk leer het meeste van naar evenementen gaan en echt de tijd te nemen om te luisteren naar een tolk, dat te volgen. En dan waarschijnlijk met een collega of twee of drie met wie je gaat daar een gesprek over te hebben. Dat is hoe ik leer. Er zijn natuurlijk ook mensen die leren van video's. Bijvoorbeeld op de Global AI Community hebben we een paar duizend video's staan. Elke keer en elke week wordt iets uitgelegd over hoe werkt deze technologie, hoe werkt deze technologie, wat heb jij ermee gebouwd. Andere mensen leren meer van artikelen lezen. Dus ja, het is heel persoonlijk natuurlijk wat de beste manier is. Dus voor mij, om te leren, ik bezoek evenementen en dan zou ik naar de Global AI Community meet-up gaan. En daar zie je allerlei meet-ups van over de hele wereld, maar ook nu in Nederland, waar je naartoe kan. Dat beantwoord eigenlijk mijn vraag die ik de ene keer oppopte. Maar hoe kom ik achter welke communities te zijn? Door inderdaad naar zo'n community te gaan waar dat weer gedeeld wordt. En dat is ook een van de bedoelingen van de AI Community Day. Als je daarheen gaat, maak je gelijk kennis met 10, 15 communities in Nederland. En we hebben bijvoorbeeld .NET Zuid, die ook natuurlijk AI-sessies aanbiedt. En die zitten meestal in Eindhoven, Helmond. Maar we hebben ook DevNetNoord, die zit in Groningen. Dus je hebt ook je lokale community. En ik denk dat dat heel belangrijk is om te leren. Je zoekt een community die jouw onderwerp heeft, die in de buurt van jou zit, waar je dus mensen uit je omgeving kan ontmoeten. En dat is ook een van de bedoelingen van de AI Community Day. En dat tijdens de Global AI Bootcamp is het in Utrecht, misschien in Nieuwegein, maar als zich dat zou verspreiden over Nederland. Voor de Global AI Community hebben we wel een plan. Daar zit wel een jaarplanning aan vast. En wat we daar eigenlijk mee bezig zijn, eerst hoe het werkte was, je hebt een community, een .NET community, een Azure community, een Google community, het maakt allemaal niet uit. En je pakt ons content op en je organiseert een event. Dus dan ben je eigenlijk een soort associate community. En dat was prima, omdat zeven jaar geleden, het was prima als je als .NET community iets met AI Day een keer per jaar. Maar dat is nu natuurlijk veranderd. En dat zien we ook. En we zien ook dat mensen nieuwe communities willen starten. Of nieuwe evenementen, nieuwe plekken om andere mensen te ontmoeten. Dus wat we dit jaar eigenlijk gaan promoten, is dat je Global AI chapters kan starten. Dus in plaats van dat we bijvoorbeeld de Azure Thursday zijn, die de Global AI Bootcamp organiseert, wordt er nu een nieuwe chapter gestart. Global AI London is er bijvoorbeeld eentje. Eigenlijk Global AI United Kingdom. Die zit in Londen. En die nemen dan onze branding over. En die presenteren zich daadwerkelijk als Global AI United Kingdom. En gaan vanuit die naam dingen organiseren. Dus dat helpt natuurlijk met de bekendheid van de Global AI community over de hele wereld. Maar het centraliseert ook alle efforts. We hebben bijvoorbeeld één YouTube kanaal. Één plek waar we content publiceren. Dus in plaats van nu alleen vanuit Nederland, van wat wij deden, en vanuit Frankrijk en Duitsland, komt er nu ook content vanuit de UK. Op hetzelfde kanaal. En hopen, er is er ook eentje begonnen in Thailand, er is er eentje begonnen in Katmandu, er is er eentje begonnen in India. En al die content komt samen. En samen is het natuurlijk in dit geval veel, veel, veel beter. En dan bouwen we inderdaad een globale community in. Iedereen draagt er zijn stukje aan bij. En dat is eigenlijk het plan waar we naar toe willen met de Global AI community. Dat overal ter wereld Global AI community chapters zijn die dat doen. Ja, mooi. Want dan zie je ook de ontwikkelingen op misschien wel mondiaal gebied, inderdaad, die verschillen. En daar kunnen we weer lering uithalen. En andere manieren van talks of, ja, mooi. Is de hele wereld bezig met generatieve AI? Nou, we hadden natuurlijk de Global AI bootcamp in maart. En daar hadden we 120 locaties in een maand. Ja, zo. En ik denk niet dat er op een agenda geen generatieve AI stond. Nee. Hoe zie jij dat ontwikkelen, het gebied van generatieve AI? Je zit dicht bij het vuur. Microsoft, OpenAI hebben een behoorlijk stevige relatie. Correct. Voor mezelf? Ja. Er gebeurt gewoon zoveel dat het gewoon bijna niet bij te houden is. Het is gewoon niet bij te houden. De handen eromheen hebben we natuurlijk alle tooling die constant in ontwikkeling is. Er is geen moment om, laat maar zeggen, even adem te halen. En je zit erin te verdiepen in zoveel. Oké, dit is het nu, nu kan ik het. Er is elke keer weer wat nieuws. Een nieuwe model, een nieuwe manier om dingen te doen. Wat hadden we? We hebben natuurlijk Rack. Dat was heel erg populair. Nu hebben we weer wat nieuws. Dat we bijvoorbeeld RAFT. Oh, die heb ik nog niet eens gehoord. Waar staat dat voor? Weet je dat? Moeten we even opzoeken. Daar is ook collega van bij, dus de hele tijd mee bezig geweest. Onderzoek gepresenteerd samen met de Universiteit van Berkeley. Je moet me er niet op vastpinnen, maar het was iets dat je een model, een soort van finetunet. Dus dat je finetuning en Rack combineert. Ik kan me er iets bij voorstellen. In iets. Dus de Rack is dat je je knowledge base, je documenten, dat je daar dingen uit zoekt. Aan de andere kant, finetunen, is dat je een model, dat je voorbeelden kan geven. En dat je die eigenlijk iets bijgeleerd is op een heel specifieke taken. En dat dan in een combinatie. Oh ja, lijkt me op zich wel logisch. Ja, dan bijvoorbeeld. Je hoort het al aan mij. Dan hoor je dat zo langskomen. Nee, dan kost het toch weer een paar dagen om daar helemaal in te duiken enzovoort. En er zijn natuurlijk allemaal dat soort tooling. Bijvoorbeeld als Microsoft Research heeft Guidance. Bijvoorbeeld. Dat is een pakket of een framework om te zorgen dat je model minder tokens verbruikt. Ja. Super cool. Heel cool. Zo zie je eigenlijk overal al die dingen maar komen en komen en komen. Dus het is echt een wervelwind wat er over je heen komt. Zeg je hiermee eigenlijk ook van, misschien moet je ook een beetje achteroverleunen in de stoel. Je kan inderdaad niet alles voorbij laten komen. Dat je even kijkt, wat zit er dan eigenlijk in die hele stroom waar je dingen uitpikt. En dat je zegt, dat is interessant voor mij, dat is interessant voor mij. Ja, ik denk dat je vooral nu moet begrijpen waar het toe in staat is. En waar je het zou kunnen inzetten om je leven makkelijker te maken. Want daar is de hoop denk ik redelijk voor. Dat ook. Net zoals met GitHub Copilot. Ga het gebruiken, zie waar het toe in staat is. Gebruik chatgpt om te zien, Bing chat, om te zien wat het allemaal kan. En dat, vooral ga het doen. Je wordt er ook beter in. Wat ik nou wel eens zie, is als mensen zeggen van, ik krijg alleen maar gekke dingen eruit. Dat ze het even hebben geprobeerd, je krijgt er niet uit wat je wil, leg je het aan de kant. Het is echt wel handig om, je moet daar gewoon een bepaalde vaardigheid in krijgen. Dus doe het. Het is net zoals sporten, als muziek leren spelen. Je moet er gewoon continu even mee bezig zijn. Het voelt een beetje ongemakkelijk in het begin, maar je wordt er steeds beter in. En als je die tijd er niet in investeert, dan kan je misschien ook beter niet starten. Want dan zijn er genoeg andere zaken die je kan oppakken. Dus je moet er continu wel proberen en kijken wat wel werkt en wat niet werkt. Ik had al wat uitgelegd over Aisha. Zullen we eens luisteren? *muziek speelt* Zetten we het er wel even aan. Dat is het mooie van een virtuele assistent, die kan je ook uitzetten. *gelach* Zo gaan dat soort dingen. De sessie die we gaan geven is misschien wel leuk. Die heet 'de robot achter de knoppen'. Dat is eigenlijk niet, dat is een mens achter de knoppen. Dat ben ik in dit geval. Dit is even een foutje. Ik ben verheugd om je hier te hebben. Ik ben Aisha. De AI van deze podcast, mag ik je een vraag stellen? Ja. Wat is het meest verrassende of indrukwekkende dat je een eenvoudig AI systeem hebt zien doen? Goeie vraag. Ik denk dat het video genereren met Sora, dat dat wel een van de meest indrukwekkende dingen is die ik heb gezien in de afgelopen tijd. Afbeeldingen genereren kan ik. Ik weet niet of het jullie gelukt is om twee dezelfde afbeeldingen naar elkaar te genereren. Nee. Maar zo'n systeem kan dat dan wel. Ja, waanzinnig. Ik vind het echt heel gaaf. Ja, dat is echt prompt ingeving. Je krijgt gewoon een heel stuk video. Ja. Zie je daar ook toepassingen in voor het spreken of bij het organiseren van jouw community days? Nou, ik zou inderdaad wel dingen genereren voor commercials, voor social media posts, voor andere dingen. Ik heb voor de AI community day bijvoorbeeld ook even een achtergrondje nodig. Ik heb eentje met een raccoon met een vlag erin. Als dat kan bewegen is dat natuurlijk echt helemaal gaaf. Inderdaad, dat trekt gelijk toch meer de aandacht die beweging moet ik zeggen. Jij was nog wel benieuwd naar die wasbeer toch? Ja, ik was wel benieuwd. Wat is het verhaal achter de wasbeer? Is er een verhaal achter? Er is geen verhaal achter de wasbeer, nee. Nou, de Microsoft Developer Advocates hebben een mascotte, een raccoon. Die gebruik ik al toen Dali 3 kwam, gebruik ik die in mijn presentaties. Dat die raccoon van alles doet. Die houdt dan een kubus vast wat dan vector space representeert en dat soort dingen. Maar die raccoon die gaat door mijn hele presentatie heen. Super leuk. Zeker als je op een bioscoop scherm mag presenteren is dat gewoon echt heel erg gaaf. En nu voor de community had ik mijn prompt natuurlijk al klaar. Dus heb ik hem een vlag gegeven en een cape aan latentrekken. En de raccoon is altijd op een verlaten planeet die Nura heet. Want die moet toch een verhaal hebben. En ook voor een demo heb ik de hele planeet Nura gegenereerd met steden en provincies. En daar heel leuk rekening over doen. Maar ja, die plaatjes komen er wel vierkant uit. En dat is natuurlijk altijd wel een dingetje. Vierkant, je bedoelt vierkant formaat. Ja, vierkant formaat. Dus ik had nu voor het eerst eigenlijk Adobe gebruikt om een achtergrond te genereren. En ik had een heel klein stukje, misschien 50 pixels gegenereerd. En gezegd, doe dat over de hele achterkant. En toen maakte hij de hele planeet netjes vormen met nieuwe sterren en helemaal in dezelfde kleuren. Dat was echt heel gaaf. Ja, creativiteit kan je er gelijk bij lossen inderdaad. Wat een fascinerend antwoord. Bedankt voor het delen. Nou, graag gedaan. En meteen een extra tool erbij natuurlijk inderdaad. Van Photoshop, daar zitten ook heel veel van die generatieve mogelijkheden in. Ik vergeet dat soms nog wel eens om dat te gebruiken. Dus dit is wel een goeie wat jij zegt. Ja, ik heb er zelf ook inderdaad. Iedere keer loop ik vast als ik een mooie powerpoint gemaakt heb met een hele mooie achtergrond. En dan passen die dimensies net niet lekker en ga je hem oprekken. En hij zou, dat kost best wel veel tijd. Dus ik ga hem ook toepassen inderdaad. En wat leuk inderdaad. Wat ik zelf wel voor verrast was, is ook het stukje muziek. Dus het muziek genereren. Ik vind het ook altijd wel leuk om vlak voor de presentatie ook een stukje muziek aan te hebben. Als mensen binnenkomen en daar zie je ook steeds meer toepassingen om daar toch wat meer customs te maken. En de muziek te genereren. Dat was ik ook wel verbaasd. Je merkt het nog wel. Nog niet helemaal soepel, maar hoe krachtig dat ook is. Nee, zeker. Ja, ik heb van de week met een van de kleindochters een tekst laten maken. En die dan inderdaad op muziek laten zetten. Ik gebruikte Suno, dat krijg je. En dan krijg je twee minuten muziek. En dat kan je dan uitbreiden. En vervolgens liep ik helemaal een beetje vast. Hoe krijg je dat dan weer aan elkaar? En in dezelfde stijl? Maar dat was in het kader van toch even snel uitproberen. Het lukte nog niet helemaal. En dan heb ik het toch afgevonden. En heb je het weer losgelaten. Maar ja, dat zijn wel hele gave dingen die je nu kan doen. Waar je eerst heel veel tijd voor nodig had. Ja, en eerst ging ik vaak naar een beeldbank of iets. Om daar dan een afbeelding te zoeken die het net niet was. En nu kan je het helemaal zelf maken. Ik vind het echt heel erg gaaf. Mooi is dat toch? Ik moet zeggen, af en toe toch nog wel lastig is om een beetje te sturen. Dan heb je toch een plaatje in je hoofd waar je een beetje naartoe wil werken. Dat je dan toch nog wel een tijdje zoet bent. Maar het zorgt wel voor een richting en een stukje creatie waarin je ondersteund wordt. Maar ik heb vaak nog wel redelijk wat prompts nodig om het plaatje dat ik dan in mijn hoofd heb eruit te komen. Bijvoorbeeld, het was de laatste conferentie in Engeland. En toen wilde ik toch even stroopwafels en dat soort zaken hebben. Maar toen heb ik ook geprobeerd de tekststroopwafels erop te zetten. En allemaal van dat soort zaken eruit te krijgen. Dus het is nog wel wat werk, maar het geeft ook plezier vind ik zelf. Henk, jij zit al lang in de technologie van kunstmatige intelligentie. Waar gaat het zich naartoe bewegen? Ook weer een goede vraag. Laten we eerst eens kijken naar de aankomende drie maanden. Zes, zeven maanden vooruit. Heel ver. Boom, Sora was daar. Ik had het nooit verwacht natuurlijk. Ik denk dat wat we deze zes, zeven maanden of drie tot zes maanden gaan zien, is dat multimodality, dat dat een heel stuk groter en meer ingezet gaat worden. Dat je een type T4 Turbo met Vision en afbeeldingen en tekst enzovoort, allemaal binnen kan krijgen, dat kan verwerken en daar overheen kan praten. Ik denk dat dat, we hebben één versie gezien. Dus ik denk dat dat echt heel veel nu gaat kopen. Zelf ook bezig met een demo voor Bilt. Dat mag ik dan wel zeggen, want het is mijn demo. Is waar we een Retrieval Augmented Generation applicatie gaan bouwen op afbeeldingen. En dan kun je zowel zoeken met tekst als met afbeeldingen. Dus je kan, geef me een rode tent en alle rode tenten komen terug. Maar dus puur gebaseerd op alleen afbeeldingen in vectors. In een vector store. Oké, dus je hebt niet het gelabeld, hier staat een rode tent op de foto, maar dat hij dat zelf in die zin herkent, dat hij dat op dat moment nodig heeft voor het beantwoorden van jouw vraag. Ja, alleen maar op basis van afbeeldingen. Waarom? - Omdat we een multimodaal embeddingmodel gebruiken. Kun je er zowel in tekst als met afbeeldingen tegenaan praten. Dus ik kan vragen om een rode tent, maar ik kan hem ook een afbeelding geven van een rode tent. En zeggen, een tent zoals dit. En dan kijkt hij ernaar of zoek me alle items die op deze afbeelding staan. En dat werkt natuurlijk omdat je normaal gesproken zou kunnen vragen, wat staat er op de foto? En dan kan hij antwoorden, er staat een rode tent op een camping, op een gras of zo. Het scheelt wel wat tagging zeg. - Ja, inderdaad. Er is natuurlijk heel veel werk waar best wel wat uitdaging in zit. Dus ik denk dat dit echt het beginnetje is waar we nu aan staan. En dan hopelijk komt er ook audio en video en allemaal dat soort dingen bij. Dan zouden wij gewoon onze podcast kunnen laten bevragen. Waar vertelt iemand iets over multimodale modellen? En dan komt hij precies met het stukje wat we net gehad hebben. Ja, dat zou wel cool zijn. - Top. Ja, en wat we natuurlijk ook gaan zien is, waar we laatst ook mee bezig geweest zijn om een demootje van te bouwen, is dat als je een podcast hebt, kan je de transcript doen. Maar als je een video hebt, wat we heel vaak doen, is ook alleen maar een transcript maken en dan social media posten. Er gebeurt zoveel andere dingen in de video die je er eigenlijk ook weer in wil hebben. Nu met GPTV Turbohead Vision kan je dit ook de afbeeldingen geven van frames van de video. Dus je geeft dat plus een transcript en dan vraag je, maak een YouTube description. En dan krijg je natuurlijk, als er alleen maar hallo of doei ingezegd wordt, en er gebeurt wat anders in de video, dan krijg je daadwerkelijk wel het hele concept. Je kan hem ook vragen, wat gebeurt er over tijd? Ja, dat is ook krachtig. Over tijd, ja. Niet alleen voor video's, maar ook voor presentaties. Het is altijd lastig om feedback te krijgen. Ik ben ook wel benieuwd hoe jullie dat in de community ook doen. Dat is een challenge die ik altijd wel vaak zie. Hoe krijg je feedback? Hoe krijg je inderdaad je improvements voor de presentatie, je verhaal? En daar zie ik dan ook heel veel waarde inderdaad. Van wanneer heb ik wat gezegd? Wat was de reactie? En dat soort zaken allemaal. Ja. Ga even daarop doorpakken. Hoe pakken jullie dat binnen de global community aan? Voor de sprekers en de sessiegevers, om feedback en weer van elkaar te leren? Ja, dat is altijd bij elke conferentie die we organiseren, is dat altijd super moeilijk. Hoe krijg je feedback? Ga je dat doen via formulier na afloop? Wat heel weinig mensen invullen, maar heel uitgebreid kan zijn? Of kies je voor de manier dat, ik noem het altijd maar de drie sleutelkaartjes of de smileys, bij de uitgang dat je veel feedback hebt? Ik denk, als je feedback over een presentatie wil, wat ik geleerd heb, is dat je één of twee collega's vraagt, die bij jou in de zaal zitten, aantekeningen maken en dan je de feedback geven. Dat is het beste. En van het publiek leer je meer van hoe het gevallen is, of ze het leuk vonden, of het interessant vonden, of het waardevol voor hen was. Maar mensen geven nooit echt daadwerkelijke feedback op je slide. Hoe je dat precies verwoorde, weet jij dat nog na een uur? Als je daarna uitloopt, dan denk je, oh dat woordje zou ik veranderd hebben als ik een presentatie had gegeven. Nee, daarom. Als ik een nieuwe presentatie doe, dan vraag ik meestal een collega om even mee in de zaal te gaan zitten, of vraag ik van tevoren, of sompteams, of ik even een drijven mag doen. En dan kijken ze inderdaad naar je woorden, naar wat er op de slide staat, match dat verhaal. En zelf help je er ook bij, als je zelf geen collega hebt die even naar je kan kijken, kan je ook wel geholpen worden. Dat is ook wel een mooie omgeving. Maar toch zegt hij, neem de analoge oplossing in dit geval. Ja, mooi. En een mooi tip inderdaad, ga je bij een collega in zijn sessie zitten, hou de rekening mee, hou de notities. Dat is heel waardevol om dat weer te delen, daar worden we allemaal weer beter van. Dankjewel Henk, weer mooie inzichten. Nog even, één keer, AI Community Day. Wanneer, waar, hoe laat? AI Community Day, 14 mei, in de fabriek, in Utrecht, van 3 tot 9. Gratis op te geven. Gratis op te geven op aicommunityday.nl Hartstikke mooi. Dankjewel dat je in onze studio wilde zijn. Als je nou geen aflevering wilt missen, zorg dan dat je even op de volgknop drukt in je favoriete podcast app. En dan krijg je vanzelf een seintje als er een nieuwe aflevering beschikbaar is. Eigenlijk altijd maandag, donderdag. Zo makkelijk is het. Dankjewel weer voor het luisteren. [Muziek] [Muziek] 