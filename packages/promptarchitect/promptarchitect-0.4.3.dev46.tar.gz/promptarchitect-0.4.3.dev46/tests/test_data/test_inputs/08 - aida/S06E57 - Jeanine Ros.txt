Hoi, leuk dat je weer luistert naar een nieuwe aflevering van AIToday Live. Ik zeg wel vaker we hebben een speciale aflevering, maar we hebben nu echt een speciale aflevering. Want we hebben het natuurlijk best wel heel vaak over AI in de zakelijke markt. Maar we gaan het vandaag over, nou eigenlijk wel iets anders vinden. En zo belangrijk dat ik deze gast heb uitgenodigd, te zeggen van kom het verhaal vertellen, want ik denk dat dit van iedereen van belang is. Mijn naam is Joop Snijder, CTO bij Aigency. Mijn naam Niels Naglé, Area Lead, Data & AI bij Info Support. En onze gast is Jeanine Ros. Jeanine, zou je jezelf willen voorstellen aan de luisteraar? Zeker, ik ben Jeanine, ik woon in Rotterdam, ik ben socioloog en ontwerper. En ik ben eigenlijk een activist op de productieve rechtvaardigheid en sociale ongelekenheden in gezondheidszorg. Ja, en het gaat eigenlijk over, reproductief gaat over krijgen van baby's. Precies. Ja, de keuze van wil ik dat of wil ik dat niet. Ja, precies. En daar heb je onderzoek naar gedaan. Ik heb hem je even voorgezet, want anders vergeten we het. Het is 'Bodies bound by barriers, a digital perspective'. En wij gaan sowieso je rapport opnemen in de show notes. Zou je in het kort kunnen vertellen waarom je aan dit onderzoek bent begonnen? En wat is eigenlijk het basisprobleem, mogen we wel zeggen, toch? Ja, ik ben begonnen in 2019 toen ik bij Women on Web ging werken. Dat is een feministische non-profit organisatie die gevestigd is in Amsterdam. En zij zorgen voor wereldwijde toegang tot online abortus. Dus als je bijvoorbeeld in een land woont waar het illegaal is, of je hebt een partner die niet wil dat je een abortus krijgt, of er zijn heel veel obstakels waar je tegenaan kan lopen in die zin. En Women on Web zorgt er dus voor dat je online de pillen kan bestellen die je nodig hebt. Het is niet zo dat je de pillen bestelt en geen hulp krijgt. Ze zijn er eigenlijk, ze zijn een beetje de online dokter voor je. Dit heet ook telemedicine, dus medicijnen via de telefoon. Dus je hebt eigenlijk altijd iemand aan de lijn die je kan bellen tijdens het proces. En zij zorgen dus al sinds 2005 voor 100.000 bestellingen. Dus dat zijn 100.000 mensen die de service gebruiken. Dus ik was toen in 2019 begonnen met hun site, hun website opnieuw opknappen. En toen zei ik, ik wil ook een site opnemen, ik wil ook een site opnemen. En toen zei ik, ik wil ook een site opnemen. Dus het was eigenlijk op een ongelukbasis gevonden dat het als medicatie kon werken. En toen was het heel even op de markt. En toen dacht de overheid van heel veel landen van, dit is niet per se hoe wij... Dit mag niet in ons soort idee van... Abortus is gewoon een soort heel geladen onderwerp voor heel veel landen. Dus ze dachten, oké, wacht, we gaan dit even terughouden. Totdat het getest is dat het ook veilig is. En dan had de FDA inderdaad gezegd, ja, het is veilig. En de World Health Organization heeft dus ook gezegd dat het een essential medicine is. Sinds 2020 volgens mij. Ik ben een beetje mijn verhaal verloren. Dat we waren bezig met... Ja, dat is een goede vraag. Dat is een hele goede vraag. We zijn deze kant ineens opgemaakt. We zitten ademloos naar je te luisteren. De vraag was... We kwamen volgens mij, maar dat is al wel weer een tijdje terug, in de lijst van onderwerpen... Waardoor die inderdaad niet naar voren kwam, niet getoond werd. Dat je daar niet zomaar achter komt, maar dat je daar een paar stappen voor hebt moeten zetten. Precies. Dus je denkt, je hebt een lijst van, je mag het niet hebben over wapens, over gevaarlijke dingen, zeg maar. En over roken, alcohol gebruik. Je krijgt gewoon een hele hoop termen van dingen die niet mogen. Een beetje wat je ziet als je naar het vliegveld gaat, wat niet in je tas mag. Dat soort dingen. En dan vraag je je dan af, wat is hier dan zo gevaarlijk aan? Dit is informatie die wel klopt. En het is gewoon bewezen door heel veel onderzoek. En we hebben zoveel mensen kunnen helpen hiermee. Wat is dan eigenlijk het probleem? Dus die kant ging dan op. Ik was dus bezig met sociale media, maar ik was toch meer geïnteresseerd in wat we posten en wat mensen niet zagen. Want dat is juist het kern van mijn onderzoek. Dat je met een post weghalen, dan raak je mensen niet, maar ze weten niet dat ze het niet geraakt worden. Want je zegt, er is feitelijke informatie, maar die wordt op een manier door de algoritmes tegengehouden. Zodat mensen niet geïnformeerd worden over feitelijke medische informatie. Klopt, ja. Dus daar was mijn interesse dan opgewekt. Daardoor was mijn interesse opgewekt. En toen ging ik mijn scriptie schrijven voor mijn studie, sociologie. En ik dacht, dit raakt me heel erg. Ik zit ook een beetje achter de schermen. Ik zit in een hele unieke positie, dat ik die cijfers kan zien. En ik leef echt deze realiteit van censorship. Dus ik dacht, ik ga hierover schrijven. En toen had ik na mijn scriptietijd een artikel geschreven, dat het een beetje toegankelijker kon zijn. Want mijn scriptie was wel wat technischer. En het ging ook heel veel over de casus zelf, maar niet echt over de kern van het onderwerp. En echt een soort call to action van, wat kunnen we hiermee? Dat had ik niet echt in mijn scriptie zitten. Dus vandaar dat artikel. En ik ben bezig met, of ik ga in september beginnen met een masterstudie, om dit verder nog uit te zoeken. Want die algoritmes veranderen wel, ook best wel snel. Ze zien ook hoeveel mensen hier last van hebben. Dus niet alleen onze organisatie, maar honderden organisaties. En we hebben nu ook een soort platform gecreëerd, Repro Uncensored heet dat. Reproductive Healthcare Uncensored. En dat is een nieuwe platform om samen te werken met andere organisaties, om hier meer bewustheid over te creëren. En wie bepaalt dan uiteindelijk dat zo'n algoritme de post niet laat zien? Is dat de overheid van op dat moment, waar die zoekactie plaatsvindt? Is het de provider van, zijn dat inderdaad de Google's en de meta's die dat doen? Wie zorgen voor dit soort censuur? Nou dat is het lastige hieraan, is dat Instagram niet per se een overheid heeft. Het is een eigen overheid in die zin. Wie bepaalt wat gezien wordt en wat niet. Het is ook wel lokaal bepaald. In Korea bijvoorbeeld, dan hebben ze onze site op de bloklist gezet. In Zuid-Korea. En in Spanje was dat ook lang zo. Dus het gaat niet per se alleen om Instagram, maar ook over Google. Dus je hebt soms te maken met lokale casussen, van Spanje bijvoorbeeld. Of je hebt te maken met de politiek over het algemeen, op welke kant gaan we op. En in 2022, precies op deze dag, was Roe vs. Wade, dat was een landmark decision van 1973, om abortus te legaliseren in Amerika. En dat was twee jaar geleden vandaag teruggedraaid. Dus eigenlijk hebben we gezien dat sinds 2020, op precies deze dag, hebben we zoveel meer last gehad van censorship. Dus dat is niet, ook al zit ik niet in Amerika, ook al zit iemand in Thailand niet in Amerika, ook al zit iemand in Nieuw-Zeeland niet in Amerika, merken we de gevolgen daarvan. Dus het gaat niet alleen maar om de beperkingen per land, maar echt als een soort global governance. Ik had het ook genoemd in mijn artikel "algorithmic governance", dat het dus bepaald wordt door de status quo van de politieke bewegingen in de wereld. En dat zie je ook in Italië, wat er nu gebeurt met verkiezingen naar meer rechtse politiek. En dat wordt een beetje gespiegeld in die zin. Dus het is een beetje moeilijk te zeggen wie precies deze beslissingen maakt. Maar wat ik dus ook schreef in een artikel over Silicon Valley, waar heel veel computer scientists te werk gaan, dat zit dus wel in Amerika. En in een boek "Silicon Values" heet het, door Gillian York, zij schreef dus over de normen en waarden die uit Silicon Valley komen, die vaak profit-driven zijn, dus geld gedreven. Ja, precies. Die meer aan de rechtere kant zitten. Ook omdat er toch meer geld in zit aan de rechterkant. En die vloeien eigenlijk door in de technologie. Dus je krijgt, dat wordt vaker gezegd, technologie is niet waardenneutraal. Dus er zitten allerlei keuzes in, waardoor alles wat daar aan besluiten wordt genomen, dat wij daar uiteindelijk ook de effecten van merken. Ja, ik denk dat het nog erger is dat we misschien niet eens doorhebben dat het effect plaatsvindt, maar dat we het gewoon nog niet ervaren. Precies. Dit is dan het voorbeeld dat, in jouw situatie zie je het gebeuren, maar ik denk dat het heel vaak wel gebeurt, maar dat we het niet doorhebben. Hoe krijg je daar zicht op? Precies. Heb je nog een voorbeeld van zoiets onzichtbaars, iets wat wij niet hebben gezien, maar waardoor jullie wel minder post krijgen? Ja, een voorbeeld is dat mijn baas bij Women on Web haar Facebook-account was geblokkeerd, om te zorgen dat zij als administrator niet meer kon posten op Women on Web. Dus dat is iets wat heel erg impliciet is eigenlijk. Dus oké, we gaan niet Women on Web blokkeren, maar als we de mensen blokkeren die de post kunnen maken, dat is eigenlijk een soort manier om een beetje die puppet master te spelen van wat zie je wel en wat zie je niet. Of de Google Core update in 2020 zorgde ervoor dat als je Women on Web intypte op Google, dat we niet bovenaan de lijst stonden van zoekresultaten. Dus dat is ook een manier om of helemaal niet te laten zien, of op pagina 4 waar je dan niet meer komt. En niemand kijkt op pagina 4. Nee, daar kom je nooit. Dus dat is wel zo'n manier van, je merkt niet als consument of als gebruiker van social media of Google, dat je getarget wordt, maar wij worden in die zin beperkt van hoe kom je op onze site en toch is dat heel erg belangrijk. Als je ons niet kan zoeken op Google, hoe kom je dan bij ons? Dan moet je weten waar je precies moet zoeken, maar dat is voor heel veel mensen niet zo makkelijk. Je weet niet wat je niet weet of hoe je het moet vinden. En nu heb je het over, we hebben ook Uncensored, een website waar meer mensen aan meedoen. Wordt die nu makkelijker gevonden dan? Of heb je nu tactieken om dat makkelijker vindbaar te maken? Ja, er zijn wel wat tactieken bedacht. Bijvoorbeeld, daar moet je dan weer van weten, een privé soort VPN gebruiken. Als je de Onion browser, Tor heet dat. Daarmee zou je die censorship kunnen omzeilen. Of als je in plaats van een A bij abortus een A-pestaartje gebruikt, dan heb je een term die de orgel niet ziet. Of ik had eens een keertje ook met ChatGPT, daar wou ik een tekst laten corrigeren, ook voor spelling en grammatica. Daar heb ik nu ook wel last van soms. Echt waar? Ik ook. Dus soms is het gewoon een handige tool. En dan zag ik bijvoorbeeld dat mijn zoekopdracht niet mocht, omdat het een politiek onderwerp was. Maar als ik dan het woord abortus vervang met 'ongewenste zwangerschap' beëindigen, dan kan het wel. O ja, want dat herkent hij gewoon nog niet als zijn synoniem. Dat zijn trucjes, synoniemen gebruiken. Wat goed. We hebben elkaar bij de boekpresentatie van Aaron Mirck gesproken. En daar gaf je volgens mij ook het voorbeeld over het adverteren. Jullie adverteren dan ook. En dat je er eigenlijk gewoon wordt uitgedrukt door de Pro-Life lobby. Ja, precies. Daar had ik dus ook onderzoek naar gedaan. Waarom ook al betalen we voor een advertentie, waarom wordt die dan alsnog weggenomen? En je ziet, terwijl onze advertenties geblokkeerd worden, zie je wel advertenties voor de abortion pill reversal. Dat is een soort anti-choice Pro-Life hoek. Stel, je hebt spijt dat je de abortuspil hebt genomen, hebben wij een pil die de effecten daarvan omdraait. En toen ging ik onderzoek doen naar hoeveel zij betalen daarvoor. En bijvoorbeeld onze advertentie kostte dan 7000 dollar. En die van hun 21.000 dollar. Dus drie keer zoveel. En je merkt dan wel, dan hebben ze wel voorkeur voor een adverteerder die net wat meer budget heeft. Want Women on Web is wel non-profit. En zo zijn veel van die organisaties non-profit of non-governmental. Er zit niet heel veel geld in, moet ik zeggen. Wel genoeg om te blijven runnen, maar er wordt niet veel aandacht. We hebben niet genoeg om... Ja, dat is ook zo'n... Even zo'n campagne inderdaad voor een ton weg te zetten om er toch bovenuit te komen. Dat is niet de middelen die er zijn om daardoor op te vallen. En dat is ook zo'n voorbeeld wat jij vroeg van dingen die wij niet zien. Uiteindelijk is het een betaalde campagne die wij nooit onder ogen zien. Maar is het niet gek dat... Want je zou kunnen zeggen als je voor abortus bent, als dat politiek geladen blijkt te zijn, dat als je tegen abortus bent, dat dat dan ook politiek geladen zou moeten zijn. Ja, daar kan ik wel boos van worden inderdaad. Waarom is... Als je voor abortus bent is het ineens een politiek onderwerp, maar als je tegen bent of ja... Als je je mening uitspreekt daarover, dan wordt het zo minder vaak gesensoreerd. En ook de comments die wij krijgen van pro-life organisatie op onze post, die worden niet weggehaald. Terwijl dat wel hate comments zijn. Ik zeg niet dat ze nooit weggehaald worden. Daar wil ik wel mee oppassen. Het is niet zo dat 100% van de posts van pro-life organisaties wel online te zien zijn. Maar ze hebben daar veel minder last van, van wat ik heb gezien. Dus eigenlijk zorgen de, in dit geval de big tech, misschien wat overheden, maar zeker zeg jij eigenlijk ook de algoritmes aan zich, voor een ongelijk speelveld op dit vlak. Ja, en wat ik dus ook benadruk is het idee dat algoritmes, ze worden gemaakt door mensen uiteindelijk. Dus dat vond ik wel interessant in mijn onderzoek, dat veel mensen dachten van, of denken van, algoritmes zijn een soort iets uit de wiskunde. Gewoon iets heel erg uit de wetenschap. Het lijkt heel erg robuust te zijn, omdat er niet altijd, het lijkt niet alsof er mensen achter zitten. En dat had ik ook geschreven over een soort metafoor, dat het een beetje een goochelaar is die een trucje speelt. En je kan er nooit achter komen hoe hij dat trucje speelt. En dat maakt het juist altijd een trucje. Zou je dat nog iets meer kunnen toelichten? Want hoe zie je die goochelaar ten opzichte van het algoritme? Dat de mensen die achter de schermen werken om die algoritmes te schrijven... Ja, die zorgen voor die optische illusie die anders de goochelaar... Die je dus ook niet kan nabootsen, want dat is dan denk ik de kern. Je kan niet nabootsen om die truc dan in dit geval na te kunnen doen, omdat je niet weet hoe de truc werkt. Ja. Van een andere analogie vond ik ook wel een mooie, waar we het dan eerder in de podcast net over hadden, is de doorn van de doornstruik. Inderdaad, je raakt iets zonder dat je het inderdaad doorhebt dat het er is. En het voelt eventjes ongemakkelijk, maar daarna denk je niet meer over na. Maar het zit overal. En dat vond ik hier ook wel. Maar goed, dat was even een hersenspinsel. Uit het artikel zelf bedoel je? Ja, uit het artikel zelf inderdaad. Precies, dat je de beslissing maakt om een roos te plukken van een tuin en je voelt de doorn en je hebt misschien ook een beetje bloed van de prik. Maar als je in dit geval niet weet dat je de pijn voelt, dus je plukt de roos, maar je hebt een beetje bloed, maar je voelt de pijn niet. Dus je ziet niet wat er is gebeurd, maar je hebt toch wel de gevolgen daarvan. Je merkt de gevolgen daarvan. Dat zit ook in het artikel ervoor, om een beetje te laten voelen hoe onzichtbaar het is. En wat zou je onze luisteraars daarin mee willen geven? Wat kunnen ze hier iets in betekenen? Moet je hier bewust van worden? Wat is belangrijk voor ze? Ik denk dat bewustwording voor mij heel erg belangrijk is, omdat ik er helemaal geen idee over had, totdat ik hier begon aan te werken. En ik me nu al zoveel in heb verdiept, dat ik het niet kan geloven dat dit niet publiek informatie is. Dus ik zou zeggen, lees hierover. Er is net een artikel hieruit gekomen van de New York Times. En ook Amnesty International is hier veel over aan het praten. Bits of Freedom is ook een organisatie in Nederland die hier specifiek over praat, over platform censorship. Wat zegt Amnesty hier bijvoorbeeld over? Ja, ze zijn onderdeel van Repro Uncensored. Dus ze staan ook echt voor het verspreiden van correcte informatie. En ze hebben dus ook een heel artikel of een heel stuk geschreven over hoe je privacy kan behouden terwijl je online dingen opzoekt. Dus met die privacy browsers bijvoorbeeld. Dus ze hebben een stuk daarover geschreven om je te helpen, met je die digital literacy te informeren over hoe je het beste toch aan je informatie kan komen terwijl er een soort politieagenten voor je of achter je scherm staan van dit mag wel en dit mag niet. Het is bijna niet eens meer een soort van, want ik geloof dat in een aantal Amerikaanse staten, ik geloof het opzoeken of dat er dingen al strafbaar genoeg is, dat ze daadwerkelijk voor je deur staan. Ja, er zijn ook tijden geweest waar het tegen hun gebruikt werd in een court case, in een uitzaak. Dus dat hun zoektermen, of dat een menstruatie app al wist dat ze zwanger waren en dat die data was toen gelekt of gebruikt tegen hun om te zeggen van je hebt wel een abortus gedaan en je wist er wel van omdat we het via de app hebben kunnen zien. Dus daarvan bewust worden is voor mij… Dat zijn de enge dingen van algoritmes, dat uiteindelijk meer van je… Ja, dit gaat verder dan de bubbel. We hebben het veel vaker over de bubbel waarin je zit, dat je niet alle informatie krijgt, of dat je heel gepolariseerd bent. Maar dit gaat verder dan de bubbel. Dit is nog wel een stapje verder. En hebben jullie, ik weet niet of jullie daar ook dingen op hebben gedaan, maar Twitter X is natuurlijk ook een platform. Geldt daar hetzelfde voor? Want daar heb je het over meta gehad. Daar hebben we veel minder dat we geblokkeerd werden of gesensoreerd werden. Daar blijkt het een soort vrijere platform te zijn. Daar heb ik ook niet heel veel onderzoek naar gedaan, dus ik durf niet veel meer te zeggen dan dat. Maar uit eigen ervaring leek het wel een veiligere plek om onze posts te posten, omdat ze tenminste wel op Twitter of X bleven. Al moet ik wel zeggen dat we alsnog te maken hadden met shadowbanning. Dat is dus dat je niet doorhebt als organisatie dat je posts minder mensen bereikt. Daar geldt precies hetzelfde. We hebben iets van 21.000 volgers en dan krijg je soms twee of drie likes. En dan denk je waar gaat die heen? Maar dat ligt denk ik ook meer aan die soort engagement algoritmes. Als je niet heel vaak post, dan krijgen mensen heel weinig te zien van je. Dus ik weet niet of het daar aangelinkt is of meer aan het... Nee, precies. Dat onderzoek is natuurlijk heel moeilijk om dat te kwantificeren van waar het dan ligt. Dat snap ik wel. Waar ik hem juist om vroeg, omdat Elon Musk zegt natuurlijk van op Twitter mag alles. En met alles bedoelt hij vaak ook echt alles. Dus ik was benieuwd of dat dan ook een beetje klopt. Jij hebt af en toe een blik achter de schermen dan. Dat was nogal een vraag die bij mij leeft. Hoe doe je het onderzoek als organisaties zijnde of je inderdaad het bereik al hebt wat je verwacht te gaan krijgen? Hoe kunnen bedrijven dat doen? Stel voor een bedrijf, denk ik van het wordt niet gevonden. Ligt het aan de manier waarop ik post, wat ik post of ligt het hieraan? Wat voor stappen kan je als organisatie daarin zetten? Dat kregen wij best wel snel te zien als organisatie. Dat onze content niet online mocht blijven door die community guideline. Dus eigenlijk zagen we dat heel snel. Maar als je inderdaad te maken met shadowbanning, dat je het niet weet, dan kan je echt een klacht indienen. Met aan vragen bijvoorbeeld van ik merk dat niet zoveel mensen raakt als ik zou willen. Klopt het dat het… En krijg je dan ook een zinnige antwoord? Nee, niet altijd. Soms krijg je gewoon een bot. Of je moet 14 dagen wachten op je antwoord. En dan krijg je soms helemaal geen antwoord. Het is best wel rommelig moet ik zeggen. Het is niet altijd 1, 2, 3, een soort makkelijk antwoord. Soms is het ook een foutje. Dat hebben we ook wel eens gehad. Dat het een soort algoritmes ding was van, oh ja, we zagen een term die niet mocht. Maar eigenlijk is in deze setting is dat wel helemaal oké. Dus het was een soort voorzorg in die zin. Maar ja, op zich zouden ze die protocols wat smoother kunnen maken. Dat het niet per ongeluk gebeurt. Dat je niet na elke post erachteraan moet rennen van, hé klopt dit wel? Dus ja, ik zou er gewoon goed op letten als je merkt dat bepaalde termen in je tekst gebruikt worden. En dat je daardoor ook minder mensen bereikt. Zou je kunnen overwegen om andere termen te gebruiken. Ook hashtags te gebruiken. Altijd op een bepaalde tijdstip. Daar moest ik ook altijd mee rekening mee houden. Zodat het precies op de juiste tijd van de dag op Instagram terecht kwam. Dat het wel in een soort goede algoritme kwam te zitten. Ja, precies. En misschien een beetje spelen met de woorden. Ja, spelen met de woorden. Dat je door de mazen van het wet, nee, door de mazen van het algoritme glipt. Of zelfs als je een organisatie hebt met veel feitjes, zoals wij hebben, gewoon heel veel tekst. Probeer het ook eens anders te laten zien met een foto die mensen raakt. Want dan heeft het algoritme minder om te kunnen filteren. Dus een post met heel veel tekst heeft dan meer triggers voor een algoritme dan een foto soms. Dus het is een hele creatieve manier om ermee om te gaan. En soms win je, soms verlies je. En dat is juist het vervelende eraan. Maar ik zou gewoon lezen over hoe je het beste mensen alert kan maken van het probleem. Want ik merk ook wel dat veel mensen, als je mensen alert maakt, staan ze aan jouw kant. En dan hebben we bijvoorbeeld een keertje gezegd van iedereen doe @metta in de comments. En dan was er een soort viral iets dat ze daar naar gingen kijken. En dan hadden we veel mensen geraakt daarmee. En ook Metta er bewust van gemaakt dat het niet oké is om ons te blokkeren. Dus voor mezelf even inderdaad spelen met woorden. Kijken naar andere content. Kijk goed naar tijden. Kijk hoe het algoritme erop reageert. Heb je twijfels? Neem ook gewoon contact op. En doe in ieder geval de reach-out van 'Goh, het is anders dan ik verwacht.' Dat zijn tips waar organisaties mee aan de slag gaan. We hebben ook een fitte week co-host, Aisha, en die wil vaak ook een vraag stellen. Kom maar op. Goedendag, mijn naam is Aisha. Ik ben de AI die deel uitmaakt van deze podcast. Mag ik je een vraag stellen? Ja hoor. Hoe voorkomen we dat AI ongelijkheid vergroot in de samenleving? Wat een toepasselijke vraag. We hebben al veel over gehad, zou je al zeggen. Maar misschien iets breder dan de social media algoritmes. Dus hoe kunnen we voorkomen dat algoritmes... Dat AI ongelijkheid vergroot in de samenleving? Ik zou zeggen... Het ligt denk ik aan de data natuurlijk, wat de algoritme krijgt om... Om te trainen. Ja, om te trainen. En als die data over precies dit onderwerp, maar ook over het algemeen, meer aan één kant staat... Dus als het niet heel erg gevarieerd is in die zin, dan heb je kans dat het ongelijkheid gaat vergroten. In de zin van, dat gaat de data spiegelen wat er al is. Dus dat zie je ook bij gezondheidszorg, AI op dit moment. Als je alleen maar witte patiënten, de data van witte patiënten gebruikt... Dan gaat die wel moeite hebben met een juiste beoordeling hebben over een patiënt die misschien niet wit is. Dus als je data gebruikt over niet feministische onderwerpen... Dan heb je kans dat die niet feministisch gaat zijn. Dus ik hoop, ik denk dat het daaraan ligt. Niet alleen aan de kant van de data zelf, maar ook aan de mensen die de data verzamelen. Hier heb ik ook wel eens een studie over gedaan. Over AI en het gebruik van AI met anticonceptievoorschrijven. En ze hadden toen data gebruikt van een kliniek in Colombia, 30.000 mensen. Hoe ga je dat dan toepassen? Dit gaat niet over ongelijkheid, maar gewoon over de data gebruik. Of goedkoop data inkopen van een low-income country in die zin. Voor een Nederlandse algoritme, hoe ga je daar dan mee om? Oh zo ja. Want dan heb je eigenlijk Colombiaanse data. En die probeer je dan op onze situatie toe te passen. Dan vergroot je de ongelijkheid in de zin dat zij dan veel minder geld zouden krijgen dan een Nederlandse studie. Omdat het makkelijker is om die data te kopen, goedkoper. Dus dan vergroot je de ongelijkheid in de zin. Dus ook ethische manieren van data inkopen. En zorg dat je dan niet alleen Colombiaanse vrouwen, maar ook vrouwen of mensen uit Thailand, Finland, Zuid-Afrika. Dat het tenminste wel een globaal plaatje schetst als je het gaat gebruiken op mensen uit de hele wereld. Precies. Ja duidelijk. Goed antwoord. Dankjewel voor je gedetailleerde uitleg. Hartstikke goed antwoord. Uiteindelijk zijn we ook heel erg benieuwd naar jouw mening over dit onderwerp. Jij verdiept je hierin. Wij zitten er niet zo sociologisch in. Dus voor ons is het allemaal buitengewoon interessant. Wat zou jij, je zit nu in de onderzoek. Wat als je onderzoek is afgelopen, waar gaat je hart naar uit? Wat worden je volgende stappen? Goede vraag. Ik denk dat ik dit onderzoek volgens mij nooit stoppen. Mijn onderzoek van twee jaar geleden is eigenlijk al outdated. Als je daar naar kijkt naar de feitjes, niet het onderzoek, maar er zijn bepaalde dingen die refreshed moeten worden. En dat gaat denk ik voor altijd nodig zijn om het accuraat te houden. Dus ik denk niet per se dat mijn onderzoek fase gaat stoppen. Omdat er ook zoveel kanten zijn naar dit onderzoek. Omdat het ook een internationaal bedrijf is of organisatie is. Zoals ik net bedoemde zijn er casussen in Zuid-Korea die heel anders zijn dan Spanje. Dus eigenlijk zou je dan onderzoek moeten doen naar die twee landen. Maar dat is ook in veel andere landen net zo. Dus ik denk niet dat mijn onderzoek gaat stoppen. Ik zou wel meer offline manieren willen vinden om dit te verspreiden. Omdat ik niet alleen in Nederland, maar ook in landen waar ze geen toegang hebben tot het internet. Dus misschien workshops organiseren voor mensen die niet weten hoe ze privé het internet kunnen gebruiken. En dat ze leren omgaan met die barrières. En weten wat de oplossingen zijn als ze een zoekopdracht toetsen die hun niet de antwoorden geeft die ze nodig hebben. Dus een kritische blik vormen op het internet of op algoritmes. Dus ja, die kant zou ik op willen als het onderzoek even op pauze zit. Ja, want het verandert natuurlijk continu. De algoritmes, de impact en dat soort zaken. Dus dat is eigenlijk ook iets wat je continu bijhoudt. Zien we al positieve of negatieve effecten op hetgeen wat we al eerder gezien hebben. Precies, het zou kunnen dat het over tien jaar heel anders eruit ziet. En dan is er misschien nog iets anders wat ik wil onderzoeken hierin. Maar ja, het is te hopen dat dit probleem opgelost zou kunnen worden. Het zou geweldig zijn. Stel je mag tien jaar vooruit kijken, wat zou je dan graag zien dat er veranderd is? Ik zou heel graag zien dat het meer open staat voor andere meningen dan wat je normaal te zien krijgt online. Dus ik merk wel dat ik er nu aan gewend ben om het altijd over abortus te hebben. Maar dat is voor heel veel mensen nog een taboe onderwerp. Dus ik zou heel graag willen dat het meer bespreekbaar zou kunnen zijn. Dat mensen niet schamen om daarover te praten. Dat ze niet schamen dat ze een abortus hebben gehad. Dat je kan zeggen dat je dat hebt gehad en dat je elkaar kunt steunen daarin. Want het is niet altijd makkelijk om dat te doen en om die beslissing te maken. Dus dat is aan één kant heel wat ik zou willen. Maar dat je daar ook openbaar over kan zijn online. Dus ook als organisatie, maar ook als individu. Dat je daar makkelijker over kan praten. En dat we daardoor meer bewustzijn kunnen creëren over wat een derde van de vrouwen zou kunnen meemaken. In de Verenigde Staten is dat een derde onder de 45 jaar. Ja, dat is gigantisch. Zoveel mensen hebben het gehad. De impact is in die zin enorm. Ja, ik denk dat je een heel belangrijk onderwerp. Gaaf dat je er zo gepassioneerd over bent. En dat je zegt van ja, hier ga ik voorlopig mee door. Ik denk dat het een hartstikke belangrijk werk is. Super bedankt dat je dit ons wilde vertellen. Dat je dit ook met de luisteraars wilde delen. Ja, de linkjes naar de artikelen die allemaal voorbij kwamen, zullen allemaal in de show notes opgenomen worden. Want volgens mij is het allemaal materiaal om rustig eens even door te lezen. Zeker, hartstikke bedankt. Dank jullie wel. Leuk dat je weer luisterde naar een aflevering van AIToday Live. Vandaag ietsje anders. Je noemt hem al speciaal, maar inderdaad Joop, heel speciaal. Maar misschien belangrijker dan alle anderen bij elkaar. Vergeet je niet te abonneren via je favoriete podcast app. En dan mis je geen aflevering. Tot de volgende keer. Volgende keer! 