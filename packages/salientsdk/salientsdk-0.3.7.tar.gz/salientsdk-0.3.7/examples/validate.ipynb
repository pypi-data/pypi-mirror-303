{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Skill Validation\n",
    "\n",
    "This example shows how to evaluate Salient's probabilistic forecasts against observations and calculate meaningful metrics. It demonstrates [validation best practices](https://salientpredictions.notion.site/Validation-0220c48b9460429fa86f577914ea5248) such as:\n",
    "\n",
    "- Proper scoring using the Continuous Ranked Probability Score (CRPS)\n",
    "  - Considers the full forecast distribution to reward both accuracy and precision\n",
    "  - Less sensitive to climatology decisions than metrics like Anomaly Correlation\n",
    "- A long backtesting period (2015-2022)\n",
    "  - Short evaluation periods are subject to noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7ff3b4c5ba10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "# Prevent wrapping on tables for readability\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "# The variable that we'll be evaluating.\n",
    "var = \"temp\"\n",
    "fld = \"vals\"\n",
    "timescale = \"sub-seasonal\"\n",
    "ref_model = \"clim\"  # Works across all timescale values.\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    # 1 year of data shows how the mechanics of the validation works.  This is\n",
    "    # not recommended for full validation, but does quickly demonstrate the theory.\n",
    "    (start_date, end_date) = (\"2021-01-01\", \"2021-12-31\")\n",
    "else:\n",
    "    # Validating 2015-2022 will replicate skill scores from hindcast_summary\n",
    "    # with split_set = \"test\"\n",
    "    (start_date, end_date) = (\"2015-01-01\", \"2022-12-31\")\n",
    "\n",
    "sk.set_file_destination(\"validation_example\")\n",
    "sk.login(\"username\", \"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set geographic bounds\n",
    "\n",
    "The Salient SDK uses a \"Location\" object to specify the geographic bounds of a request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26.125, -97.375)\n"
     ]
    }
   ],
   "source": [
    "if True:  # single lat/lon point\n",
    "    loc = sk.Location(26.125, -97.375)  # SpaceX spaceport\n",
    "elif False:  # \"shapefile\" - gridded analysis of the ERCOT footprint\n",
    "    lons = [-107, -98, -94, -94, -100, -103, -103, -107]\n",
    "    lats = [32, 25, 29, 34, 36, 36, 32, 32]\n",
    "    shape_file = sk.upload_shapefile(list(zip(lons, lats)), \"ercot_simple\", force=False)\n",
    "    loc = sk.Location(shapefile=shape_file)\n",
    "elif True:  # \"location_file\"\n",
    "    loc = sk.Location(\n",
    "        location_file=sk.upload_location_file(\n",
    "            lats=[37.7749, 33.9416, 32.7336],\n",
    "            lons=[-122.4194, -118.4085, -117.1897],\n",
    "            names=[\"SFO\", \"LAX\", \"SAN\"],\n",
    "            geoname=\"CA_Airports\",\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Invalid location type\")\n",
    "\n",
    "print(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast\n",
    "\n",
    "The [`forecast_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.forecast_timeseries) API endpoint and SDK function returns Salient's native temporally granular weekly/monthly/quarterly forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             file_name        date  model\n",
      "0    validation_example/forecast_timeseries_3275aee...  2021-01-03  blend\n",
      "1    validation_example/forecast_timeseries_904f9fc...  2021-01-03   clim\n",
      "2    validation_example/forecast_timeseries_95c7514...  2021-01-10  blend\n",
      "3    validation_example/forecast_timeseries_2e45506...  2021-01-10   clim\n",
      "4    validation_example/forecast_timeseries_d7d535b...  2021-01-17  blend\n",
      "..                                                 ...         ...    ...\n",
      "99   validation_example/forecast_timeseries_abf18bf...  2021-12-12   clim\n",
      "100  validation_example/forecast_timeseries_754b1b4...  2021-12-19  blend\n",
      "101  validation_example/forecast_timeseries_d290771...  2021-12-19   clim\n",
      "102  validation_example/forecast_timeseries_55f61a5...  2021-12-26  blend\n",
      "103  validation_example/forecast_timeseries_42c20e5...  2021-12-26   clim\n",
      "\n",
      "[104 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "date_range = sk.get_hindcast_dates(start_date=start_date, end_date=end_date, timescale=timescale)\n",
    "\n",
    "fcst = sk.forecast_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    field=fld,\n",
    "    date=date_range,  # OK to request multiple forecast dates\n",
    "    timescale=timescale,\n",
    "    model=[\"blend\", ref_model],\n",
    "    reference_clim=\"30_yr\",  # this is the climatology used by data_timeseries\n",
    "    verbose=False,\n",
    "    force=False,\n",
    "    strict=False,  # There is missing data in 2020.  Work around it.\n",
    ")\n",
    "\n",
    "# Because we requested multiple forecast dates and models, the result is a vector of file names\n",
    "print(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 1kB\n",
      "Dimensions:                 (quantiles: 23, lead_weekly: 5, nbnds: 2,\n",
      "                             location: 1)\n",
      "Coordinates:\n",
      "  * quantiles               (quantiles) float64 184B 0.01 0.025 ... 0.975 0.99\n",
      "    forecast_period_weekly  (lead_weekly, nbnds) datetime64[ns] 80B 2020-12-3...\n",
      "  * lead_weekly             (lead_weekly) int32 20B 1 2 3 4 5\n",
      "    lat                     (location) float64 8B 26.12\n",
      "    lon                     (location) float64 8B -97.38\n",
      "    month                   int32 4B 12\n",
      "    forecast_date_weekly    datetime64[ns] 8B 2020-12-30\n",
      "Dimensions without coordinates: nbnds, location\n",
      "Data variables:\n",
      "    vals_weekly             (lead_weekly, location, quantiles) float64 920B 1...\n",
      "Attributes:\n",
      "    clim_period:  ['1990-01-01', '2019-12-31']\n",
      "    short_name:   temp\n",
      "    timescale:    sub-seasonal\n",
      "    region:       north-america\n"
     ]
    }
   ],
   "source": [
    "# Example forecast file is for a single model and a single forecast_date\n",
    "print(xr.load_dataset(fcst[\"file_name\"].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical\n",
    "\n",
    "Download daily historical values from [`data_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.data_timeseries) and then aggregate to match the forecasts, so that we can ensure that all forecasts use the same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:  (time: 410, location: 1)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 3kB 2020-12-27 2020-12-28 ... 2022-02-09\n",
      "    lat      (location) float64 8B 26.12\n",
      "    lon      (location) float64 8B -97.38\n",
      "Dimensions without coordinates: location\n",
      "Data variables:\n",
      "    vals     (time, location) float64 3kB 18.9 21.31 22.17 ... 15.58 14.28 14.44\n",
      "Attributes:\n",
      "    long_name:   2 metre temperature\n",
      "    units:       degC\n",
      "    clim_start:  1990-01-01\n",
      "    clim_end:    2019-12-31\n"
     ]
    }
   ],
   "source": [
    "# Get additional historical data beyond end_date to make sure we have enough\n",
    "# observed days to compare with the final forecast.\n",
    "duration = {\"sub-seasonal\": 8 * 5, \"seasonal\": 31 * 3, \"long-range\": 95 * 4}[timescale]\n",
    "hist = sk.data_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    field=fld,\n",
    "    start=np.datetime64(start_date) - np.timedelta64(5, \"D\"),\n",
    "    end=np.datetime64(end_date) + np.timedelta64(duration, \"D\"),\n",
    "    frequency=\"daily\",\n",
    "    # reference_clim=\"30_yr\",  implicitly uses 30 yr climatology\n",
    "    verbose=False,\n",
    "    force=False,\n",
    ")\n",
    "print(xr.load_dataset(hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Skill Metrics\n",
    "\n",
    "Compare the forecast and observed datasets to see how well they match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 76B\n",
      "Dimensions:      (location: 1, lead_weekly: 5)\n",
      "Coordinates:\n",
      "    lat          (location) float64 8B 26.12\n",
      "    lon          (location) float64 8B -97.38\n",
      "  * lead_weekly  (lead_weekly) int32 20B 1 2 3 4 5\n",
      "Dimensions without coordinates: location\n",
      "Data variables:\n",
      "    crps         (lead_weekly, location) float64 40B 0.4233 0.757 ... 0.8848\n",
      "Attributes:\n",
      "    clim_period:  ['1990-01-01', '2019-12-31']\n",
      "    short_name:   crps\n",
      "    timescale:    sub-seasonal\n",
      "    region:       north-america\n",
      "    long_name:    CRPS\n"
     ]
    }
   ],
   "source": [
    "skill_fcst = sk.skill.crps(observations=hist, forecasts=fcst[fcst[\"model\"] == \"blend\"])\n",
    "print(skill_fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Relative Skill\n",
    "\n",
    "CRPS shows skill without context. A \"skill score\" will compare two different skills for a relative value. In the example below, we will compare the Salient blend with climatology (historical averages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 76B\n",
      "Dimensions:      (location: 1, lead_weekly: 5)\n",
      "Coordinates:\n",
      "    lat          (location) float64 8B 26.12\n",
      "    lon          (location) float64 8B -97.38\n",
      "  * lead_weekly  (lead_weekly) int32 20B 1 2 3 4 5\n",
      "Dimensions without coordinates: location\n",
      "Data variables:\n",
      "    crpss        (lead_weekly, location) float64 40B 0.5714 0.252 ... 0.1038\n",
      "Attributes:\n",
      "    short_name:  crpss\n",
      "    long_name:   CRPSS\n"
     ]
    }
   ],
   "source": [
    "# Calculate the \"reference\" skill score.  This is what we are comparing Salient Blend against.\n",
    "skill_ref = sk.skill.crps(observations=hist, forecasts=fcst[fcst[\"model\"] == ref_model])\n",
    "\n",
    "skill_score = sk.skill.crpss(forecast=skill_fcst, reference=skill_ref)\n",
    "\n",
    "print(skill_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble all results into a single table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   location  lead_weekly  Reference CRPS  Salient CRPS  CRPS Skill Score (%)\n",
      "0         0            1            0.99          0.42                  57.1\n",
      "1         0            2            1.01          0.76                  25.2\n",
      "2         0            3            1.01          0.81                  20.1\n",
      "3         0            4            1.00          0.84                  16.1\n",
      "4         0            5            0.99          0.88                  10.4\n"
     ]
    }
   ],
   "source": [
    "skill_table = (\n",
    "    (\n",
    "        xr.merge(\n",
    "            [\n",
    "                (skill_ref.rename({\"crps\": \"Reference CRPS\"})).round(2),\n",
    "                skill_fcst.rename({\"crps\": \"Salient CRPS\"}).round(2),\n",
    "                (skill_score * 100).rename({\"crpss\": \"CRPS Skill Score (%)\"}).round(1),\n",
    "            ]\n",
    "        )\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "    )\n",
    "    .dropna(how=\"any\")\n",
    "    .drop(columns=[\"lat\", \"lon\"])\n",
    ")\n",
    "if \"location\" in skill_table.columns and loc.location_file is None:\n",
    "    skill_table = skill_table.drop(columns=[\"location\"])\n",
    "\n",
    "\n",
    "print(skill_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to pre-computed skill\n",
    "\n",
    "Salient pre-calculates skill metrics as a convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Lead  Reference CRPS  Salient CRPS  Salient CRPS Skill Score (%)\n",
      "0  Week 1            0.96          0.38                          60.1\n",
      "1  Week 2            0.96          0.72                          25.1\n",
      "2  Week 3            0.96          0.84                          11.7\n",
      "3  Week 4            0.96          0.88                           8.1\n",
      "4  Week 5            0.96          0.88                           8.2\n"
     ]
    }
   ],
   "source": [
    "skill_summ = pd.read_csv(\n",
    "    sk.hindcast_summary(\n",
    "        loc=loc,\n",
    "        interp_method=\"linear\",\n",
    "        metric=\"crps\",\n",
    "        variable=var,\n",
    "        timescale=timescale,\n",
    "        reference=ref_model,\n",
    "        split_set=\"test\",\n",
    "    )\n",
    ")\n",
    "print(skill_summ.drop(columns=\"Reference Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set fast=False for consistent calculations.\n"
     ]
    }
   ],
   "source": [
    "# \"fast\" mode does not download forecasts for the full test period,\n",
    "# so results aren't expected to be consistent.\n",
    "if fast:\n",
    "    print(\"Set fast=False for consistent calculations.\")\n",
    "else:\n",
    "    skill_fcst[\"crps\"].plot(x=\"lead_weekly\", label=\"manual calculation\")\n",
    "    plt.plot(skill_fcst.lead_weekly, skill_summ[\"Salient CRPS\"], label=\"hindcast_sumary\")\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
