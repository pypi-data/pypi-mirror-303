<?xml version="1.0" encoding="UTF-8"?>
<testsuites tests="64" failures="0" errors="0" time="412.613167">
	<testsuite tests="64" failures="0" time="406.650000" name="go.temporal.io/server/tests/xdc" timestamp="2024-10-18T13:42:23Z">
		<properties>
			<property name="go.version" value="go1.22.6 linux/amd64"></property>
		</properties>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback" time="9.010000">
			<skipped message="=== RUN   TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback&#xA;2024-10-18T13:42:45.184Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:45.442Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:45.577Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:45.578Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:45.578Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:46.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:46.184Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:46.402Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:46.403Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby-adv-vis&#34;, &#34;host&#34;: &#34;127.0.4.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:46.404Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;standby-adv-vis&#34;, &#34;host&#34;: &#34;127.0.4.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.4.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:46.441Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:46.467Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:46.468Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:46.468Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:46.469Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:46.469Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:46.469Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:46.469Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:46.469Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:46.579Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:47.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:47.190Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:47.320Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:47.322Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:47.323Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:47.442Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:47.579Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:47.580Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:47.582Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;rpc-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 2400, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:47.583Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;visibility-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 50, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:47.583Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;namespace-replication&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 10, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:47.584Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:47.613Z&#x9;info&#x9;Register namespace succeeded&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;wf-namespace-id&#34;: &#34;c547a13a-a724-426a-b42f-9d4f3a6956b8&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/namespace_handler.go:284&#34;}&#xA;2024-10-18T13:42:47.882Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:47.884Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:47.885Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;c771e221&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:47.886Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:47.886Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:47.886Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:47.886Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:47.887Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:48.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:48.043Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;long-poll-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 1200, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:48.046Z&#x9;info&#x9;Started Worker&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7138&#34;, &#34;Namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;TaskQueue&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;WorkerID&#34;: &#34;server-worker@3262@fv-az913-342@test-xdc-search-attr-nrdrn&#34;, &#34;logging-call-at&#34;: &#34;/opt/hostedtoolcache/go/1.22.6/x64/src/sync/oncefunc.go:57&#34;}&#xA;2024-10-18T13:42:48.053Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:48.053Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:48.053Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;fv-az913-342:184f36ff-a3a5-4b3a-aed3-7f18b04c315a&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:48.053Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;service&#34;: &#34;matching&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-nrdrn&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:48.056Z&#x9;info&#x9;loaded user data from db&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;user-data-version&#34;: 0, &#34;timestamp&#34;: &#34;1970-01-01T00:00:00.000Z&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/user_data_manager.go:551&#34;}&#xA;2024-10-18T13:42:48.184Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:48.236Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:48.239Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:48.240Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;c771e221&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:48.240Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:48.240Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:48.240Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:48.241Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:48.241Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:48.441Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:48.443Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:48.443Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:48.467Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:48.467Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:48.468Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:48.936Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:48.937Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:48.937Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;c771e221&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:48.938Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:48.938Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:48.938Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:48.938Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:48.939Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:49.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:49.185Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:49.308Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:49.308Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:49.309Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;c771e221&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:49.310Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:49.310Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:49.310Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:49.310Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:49.310Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:49.443Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:49.487Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:49.490Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:49.491Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:49.656Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:49.658Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:49.660Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:50.031Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:50.184Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:50.444Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:50.445Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:50.446Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;rpc-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 2400, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.447Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;visibility-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 50, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.447Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;namespace-replication&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 10, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.448Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.469Z&#x9;info&#x9;Register namespace succeeded&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/namespace_handler.go:284&#34;}&#xA;2024-10-18T13:42:50.480Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;long-poll-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 1200, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.482Z&#x9;info&#x9;Started Worker&#x9;{&#34;Namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;TaskQueue&#34;: &#34;history-replication-dlq-test-task-queue&#34;, &#34;WorkerID&#34;: &#34;3262@fv-az913-342@&#34;, &#34;logging-call-at&#34;: &#34;/opt/hostedtoolcache/go/1.22.6/x64/src/sync/oncefunc.go:57&#34;}&#xA;2024-10-18T13:42:50.489Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;fv-az913-342:f3ea6bd7-2df0-43ce-af23-f0cbb73a9903&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.490Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;service&#34;: &#34;matching&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:50.490Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/3&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.489Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;history-replication-dlq-test-task-queue&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.489Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;history-replication-dlq-test-task-queue&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.494Z&#x9;info&#x9;loaded user data from db&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;user-data-version&#34;: 0, &#34;timestamp&#34;: &#34;1970-01-01T00:00:00.000Z&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/user_data_manager.go:551&#34;}&#xA;2024-10-18T13:42:50.501Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/2&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Force&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.501Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/1&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Force&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.503Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/1&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Force&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.503Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/2&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Force&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.505Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;/_sys/history-replication-dlq-test-task-queue/3&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Force&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:50.936Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:50.937Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:50.938Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:51.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:51.184Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:51.252Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;fv-az913-342:e868e202-9377-411b-b8ee-7df5541c8472&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:51.253Z&#x9;info&#x9;Started Worker&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7138&#34;, &#34;Namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;TaskQueue&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;WorkerID&#34;: &#34;server-worker@3262@fv-az913-342@history-replication-dlq-test-namespace&#34;, &#34;logging-call-at&#34;: &#34;/opt/hostedtoolcache/go/1.22.6/x64/src/sync/oncefunc.go:57&#34;}&#xA;2024-10-18T13:42:51.253Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:51.255Z&#x9;info&#x9;loaded user data from db&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;user-data-version&#34;: 0, &#34;timestamp&#34;: &#34;1970-01-01T00:00:00.000Z&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/user_data_manager.go:551&#34;}&#xA;2024-10-18T13:42:51.257Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:51.307Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:51.308Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:51.309Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:51.334Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;service&#34;: &#34;history&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;history-replication-dlq-test-namespace&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:51.354Z&#x9;error&#x9;history replication task encountered error&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;290b11bc-0782-49d4-b4bb-07377b478818&#34;, &#34;queue-task-id&#34;: 1048586, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).HandleErr&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:320&#xA;go.temporal.io/server/common/backoff.ThrottleRetry.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:62&#xA;go.temporal.io/server/common/backoff.ThrottleRetryContext&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:89&#xA;go.temporal.io/server/common/backoff.ThrottleRetry&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:63&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:327&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:51.354Z&#x9;error&#x9;replication task: 1048586 encountered nack event&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).Nack&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:333&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:51.389Z&#x9;error&#x9;history replication task encountered error&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;290b11bc-0782-49d4-b4bb-07377b478818&#34;, &#34;queue-task-id&#34;: 1048590, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).HandleErr&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:320&#xA;go.temporal.io/server/common/backoff.ThrottleRetry.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:62&#xA;go.temporal.io/server/common/backoff.ThrottleRetryContext&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:89&#xA;go.temporal.io/server/common/backoff.ThrottleRetry&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:63&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:327&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:51.389Z&#x9;error&#x9;replication task: 1048590 encountered nack event&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).Nack&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:333&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:51.414Z&#x9;error&#x9;history replication task encountered error&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;290b11bc-0782-49d4-b4bb-07377b478818&#34;, &#34;queue-task-id&#34;: 1048597, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).HandleErr&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:213&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:320&#xA;go.temporal.io/server/common/backoff.ThrottleRetry.func1&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:62&#xA;go.temporal.io/server/common/backoff.ThrottleRetryContext&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:89&#xA;go.temporal.io/server/common/backoff.ThrottleRetry&#xA;&#x9;/home/runner/work/temporal/temporal/common/backoff/retry.go:63&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:327&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:51.414Z&#x9;error&#x9;replication task: 1048597 encountered nack event&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;error&#34;: &#34;failed to apply replication task&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).Nack&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:198&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).executeTask&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:333&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).processTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:287&#xA;go.temporal.io/server/common/tasks.(*SequentialScheduler[...]).pollTaskQueue&#xA;&#x9;/home/runner/work/temporal/temporal/common/tasks/sequential_scheduler.go:258&#xA;2024-10-18T13:42:52.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:52.033Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:52.033Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:52.185Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:52.324Z&#x9;error&#x9;Enqueued replication task to DLQ&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;xdc-source-shard-id&#34;: 1, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;queue-task-id&#34;: 1048586, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-replication-task&#34;: &#34;namespace_id:\&#34;0761b3df-8764-4533-9209-1cf7ae80bc6f\&#34;  workflow_id:\&#34;b798e647-d4dd-4a43-aed2-4889b1bf179e\&#34;  run_id:\&#34;290b11bc-0782-49d4-b4bb-07377b478818\&#34;  task_type:TASK_TYPE_REPLICATION_HISTORY  version:1  first_event_id:1  next_event_id:3  task_id:1048586  visibility_time:{seconds:1729258971  nanos:333480764}&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:274&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskTrackerImpl).LowWatermark&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task_tracker.go:150&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).ackMessage&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:242&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).sendEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:198&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:52.326Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;service&#34;: &#34;history&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:52.333Z&#x9;error&#x9;Enqueued replication task to DLQ&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;xdc-source-shard-id&#34;: 1, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;queue-task-id&#34;: 1048590, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-replication-task&#34;: &#34;namespace_id:\&#34;0761b3df-8764-4533-9209-1cf7ae80bc6f\&#34;  workflow_id:\&#34;b798e647-d4dd-4a43-aed2-4889b1bf179e\&#34;  run_id:\&#34;290b11bc-0782-49d4-b4bb-07377b478818\&#34;  task_type:TASK_TYPE_REPLICATION_HISTORY  version:1  first_event_id:3  next_event_id:4  task_id:1048590  visibility_time:{seconds:1729258971  nanos:363128915}&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:274&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskTrackerImpl).LowWatermark&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task_tracker.go:150&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).ackMessage&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:242&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).sendEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:198&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:52.342Z&#x9;error&#x9;Enqueued replication task to DLQ&#x9;{&#34;cluster-name&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;xdc-source-shard-id&#34;: 1, &#34;wf-namespace-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;wf-id&#34;: &#34;b798e647-d4dd-4a43-aed2-4889b1bf179e&#34;, &#34;wf-run-id&#34;: &#34;0761b3df-8764-4533-9209-1cf7ae80bc6f&#34;, &#34;queue-task-id&#34;: 1048597, &#34;xdc-source-cluster&#34;: &#34;2aa6d03eea424633a7fd5851e5507019_active&#34;, &#34;xdc-replication-task&#34;: &#34;namespace_id:\&#34;0761b3df-8764-4533-9209-1cf7ae80bc6f\&#34;  workflow_id:\&#34;b798e647-d4dd-4a43-aed2-4889b1bf179e\&#34;  run_id:\&#34;290b11bc-0782-49d4-b4bb-07377b478818\&#34;  task_type:TASK_TYPE_REPLICATION_HISTORY  version:1  first_event_id:4  next_event_id:6  task_id:1048597  visibility_time:{seconds:1729258971  nanos:402624506}&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskImpl).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task.go:618&#xA;go.temporal.io/server/service/history/replication.(*ExecutableHistoryTask).MarkPoisonPill&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_history_task.go:274&#xA;go.temporal.io/server/service/history/replication.(*ExecutableTaskTrackerImpl).LowWatermark&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/executable_task_tracker.go:150&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).ackMessage&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:242&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).sendEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:198&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;    history_replication_signals_and_updates_test.go:210: flaky test&#xA;--- SKIP: TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback (9.01s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId" time="0.000000">
			<skipped message="=== RUN   TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId&#xA;    history_replication_signals_and_updates_test.go:362: flaky test&#xA;--- SKIP: TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated" time="0.000000">
			<skipped message="=== RUN   TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated&#xA;    nexus_state_replication_test.go:102: flaky test&#xA;--- SKIP: TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover" time="0.000000">
			<skipped message="=== RUN   TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover&#xA;    failover_test.go:1951: flaky test&#xA;--- SKIP: TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover" time="0.000000">
			<skipped message="=== RUN   TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover&#xA;    failover_test.go:1855: flaky test&#xA;--- SKIP: TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamEnabled/TestWorkflowReplicationTaskFailure" time="8.020000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestApplyReplicationEventRevivesInUseTombstones" time="8.990000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAdmittedUpdateWithConflictingId" time="3.660000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamEnabled" time="30.070000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyCompleteUpdateWithConflictingId" time="4.200000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestAdvVisCrossDCTestSuite/TestSearchAttributes" time="17.780000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataEntriesAreReplicatedOnDemand" time="8.980000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionReappliesSignals" time="2.150000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataIsReplicatedFromActiveToPassive" time="2.630000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionReappliesUpdates" time="3.560000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestAdvVisCrossDCTestSuite" time="39.560000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestUpdateCompletedAfterFailoverCannotBeCompletedAgainAfterFailback" time="5.420000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataIsReplicatedFromPassiveToActive" time="7.570000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamDisabled/TestWorkflowReplicationTaskFailure" time="10.610000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite" time="49.200000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/success" time="0.210000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/handler_error" time="0.100000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/redirect_disabled_by_header" time="0.010000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive" time="7.910000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCompleteOperationForwardedFromStandbyToActive" time="1.570000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataTombstonesAreReplicated" time="9.510000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/success" time="0.130000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/operation_error" time="0.060000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/handler_error" time="0.230000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/redirect_disabled_by_header" time="0.010000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive" time="1.470000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamDisabled" time="25.820000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite" time="60.280000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite" time="21.420000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamEnabled/TestWorkflowReplicationTaskFailure" time="8.610000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamEnabled" time="21.730000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestActivityHeartbeatFailover" time="27.260000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestForceReplicateResetWorkflow_BaseWorkflowNotFound" time="16.440000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusCallbackReplicated" time="22.930000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamDisabled/TestWorkflowReplicationTaskFailure" time="10.960000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusOperationCancelationReplicated" time="2.770000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamDisabled" time="19.740000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite" time="97.360000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestReplicateHistoryEvents_ForceReplicationScenario" time="14.200000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite" time="37.160000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestContinueAsNewFailover" time="20.800000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestResetWorkflow_SyncWorkflowState" time="12.680000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite" time="54.830000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceMigration_ClosedWorkflow" time="18.550000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceMigration_ResetWorkflow" time="12.540000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceWorkflowTaskClose_WithClusterReconnect" time="34.170000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestLocalNamespaceMigration" time="26.180000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestNamespaceFailover" time="16.059000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestResetWorkflowFailover" time="22.900000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestSignalFailover" time="16.239000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestSimpleWorkflowFailover" time="21.290000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestStartWorkflowExecution_Failover_WorkflowIDReusePolicy" time="16.200000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestStickyWorkflowTaskFailover" time="27.510000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestTerminateFailover" time="16.160000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestTransientWorkflowTaskFailover" time="17.080000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestUserTimerFailover" time="17.150000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestWorkflowRetryFailAndFailover" time="16.160000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestWorkflowRetryStartAndFailover" time="17.920000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite" time="355.130000"></testcase>
	</testsuite>
</testsuites>