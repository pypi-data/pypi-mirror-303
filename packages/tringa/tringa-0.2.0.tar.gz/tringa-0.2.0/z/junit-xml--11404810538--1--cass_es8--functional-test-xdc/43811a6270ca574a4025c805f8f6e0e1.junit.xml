<?xml version="1.0" encoding="UTF-8"?>
<testsuites tests="64" failures="0" errors="0" time="429.682215">
	<testsuite tests="64" failures="0" time="423.698000" name="go.temporal.io/server/tests/xdc" timestamp="2024-10-18T13:42:17Z">
		<properties>
			<property name="go.version" value="go1.22.6 linux/amd64"></property>
		</properties>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback" time="6.000000">
			<skipped message="=== RUN   TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback&#xA;2024-10-18T13:42:38.890Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:39.027Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.030Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.031Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.031Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:39.032Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.032Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.032Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.032Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.033Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.075Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.076Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.076Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.077Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.077Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.077Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.077Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.077Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.112Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.114Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:39.115Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.116Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.116Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.117Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.117Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.117Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.117Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.143Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.144Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.144Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.145Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.145Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.145Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.145Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.145Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.191Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.191Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby-adv-vis&#34;, &#34;host&#34;: &#34;127.0.4.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.193Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;standby-adv-vis&#34;, &#34;host&#34;: &#34;127.0.4.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.4.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:39.815Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.817Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:39.818Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.819Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.820Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.820Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.820Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.820Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.820Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.830Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:39.830Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:39.831Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:39.831Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:39.831Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:39.831Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:39.832Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:39.832Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:39.891Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:40.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:40.115Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:40.116Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:40.116Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:40.817Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:40.891Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:41.031Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:41.075Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:41.076Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:41.077Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:41.077Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:41.077Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:41.077Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:41.078Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:41.078Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:41.117Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:41.118Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby-adv-vis&#34;, &#34;xdc-target-cluster&#34;: &#34;active-adv-vis&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:41.120Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;rpc-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 2400, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.121Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;visibility-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 50, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.121Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;namespace-replication&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 10, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.122Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.143Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:41.144Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:41.144Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:41.145Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:41.145Z&#x9;info&#x9;Register namespace succeeded&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;wf-namespace-id&#34;: &#34;657c3992-5ee4-4cf5-bf70-b24a742eba35&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/namespace_handler.go:284&#34;}&#xA;2024-10-18T13:42:41.145Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:41.145Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:41.145Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:41.145Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:41.316Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:41.319Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:41.320Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:41.694Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;component&#34;: &#34;long-poll-handler&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 1200, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.697Z&#x9;info&#x9;Started Worker&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7138&#34;, &#34;Namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;TaskQueue&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;WorkerID&#34;: &#34;server-worker@3513@fv-az2025-999@test-xdc-search-attr-oardd&#34;, &#34;logging-call-at&#34;: &#34;/opt/hostedtoolcache/go/1.22.6/x64/src/sync/oncefunc.go:57&#34;}&#xA;2024-10-18T13:42:41.704Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Activity&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:41.705Z&#x9;info&#x9;Quota changed&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;service&#34;: &#34;matching&#34;, &#34;component&#34;: &#34;persistence&#34;, &#34;scope&#34;: &#34;namespace&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;current-quota&#34;: null, &#34;new-quota&#34;: 0, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/quotas/calculator/logged_calculator.go:124&#34;}&#xA;2024-10-18T13:42:41.704Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;fv-az2025-999:252277b3-9015-4331-8c01-c569f3cabc96&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:41.704Z&#x9;info&#x9;Started physicalTaskQueueManager&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;wf-task-queue-name&#34;: &#34;temporal-sys-per-ns-tq&#34;, &#34;wf-task-queue-type&#34;: &#34;Workflow&#34;, &#34;wf-namespace&#34;: &#34;test-xdc-search-attr-oardd&#34;, &#34;worker-build-id&#34;: &#34;_unversioned_&#34;, &#34;lifecycle&#34;: &#34;Started&#34;, &#34;cause&#34;: &#34;Poll&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/physical_task_queue_manager.go:288&#34;}&#xA;2024-10-18T13:42:41.708Z&#x9;info&#x9;loaded user data from db&#x9;{&#34;cluster-name&#34;: &#34;active-adv-vis&#34;, &#34;host&#34;: &#34;127.0.3.1:7136&#34;, &#34;component&#34;: &#34;matching-engine&#34;, &#34;user-data-version&#34;: 0, &#34;timestamp&#34;: &#34;1970-01-01T00:00:00.000Z&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/matching/user_data_manager.go:551&#34;}&#xA;2024-10-18T13:42:41.817Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:41.830Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:41.830Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:41.831Z&#x9;error&#x9;service failures&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;operation&#34;: &#34;StreamWorkflowReplicationMessages&#34;, &#34;hash&#34;: &#34;371000be&#34;, &#34;grpc_code&#34;: &#34;Internal&#34;, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).logErrors&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:408&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).HandleError&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:378&#xA;go.temporal.io/server/common/rpc/interceptor.(*TelemetryInterceptor).StreamIntercept&#xA;&#x9;/home/runner/work/temporal/temporal/common/rpc/interceptor/telemetry.go:235&#xA;google.golang.org/grpc.(*Server).processStreamingRPC&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1694&#xA;google.golang.org/grpc.(*Server).handleStream&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1808&#xA;google.golang.org/grpc.(*Server).serveStreams.func2.1&#xA;&#x9;/home/runner/go/pkg/mod/google.golang.org/grpc@v1.66.0/server.go:1029&#xA;2024-10-18T13:42:41.831Z&#x9;info&#x9;AdminStreamReplicationMessages server -&gt; client encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;unknown cluster ID: 1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1887&#34;}&#xA;2024-10-18T13:42:41.831Z&#x9;info&#x9;AdminStreamReplicationMessages stopped.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1912&#34;}&#xA;2024-10-18T13:42:41.832Z&#x9;info&#x9;AdminStreamReplicationMessages client -&gt; server encountered error&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;error&#34;: &#34;rpc error: code = Canceled desc = context canceled&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1860&#34;}&#xA;2024-10-18T13:42:41.832Z&#x9;error&#x9;StreamReceiver encountered channel close&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#34;}&#xA;go.temporal.io/server/common/log.(*zapLogger).Error&#xA;&#x9;/home/runner/work/temporal/temporal/common/log/zap_logger.go:154&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).processMessages&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:375&#xA;go.temporal.io/server/service/history/replication.(*StreamReceiverImpl).recvEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:226&#xA;go.temporal.io/server/service/history/replication.WrapEventLoop&#xA;&#x9;/home/runner/work/temporal/temporal/service/history/replication/stream.go:76&#xA;2024-10-18T13:42:41.832Z&#x9;info&#x9;StreamReceiver shutting down.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:166&#34;}&#xA;2024-10-18T13:42:41.891Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:42.032Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:42.178Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:42.180Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:42.181Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:42.421Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:42.424Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:42.425Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:42.817Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:42.891Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:43.031Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:43.033Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;active&#34;, &#34;xdc-target-cluster&#34;: &#34;standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:43.033Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-target-cluster&#34;: &#34;active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:43.076Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;active&#34;, &#34;host&#34;: &#34;127.0.1.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:43.076Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:43.077Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;standby&#34;, &#34;host&#34;: &#34;127.0.5.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.5.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;active&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:43.143Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;cluster1&#34;, &#34;host&#34;: &#34;127.0.2.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:43.144Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:43.145Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;cluster2&#34;, &#34;host&#34;: &#34;127.0.6.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.6.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:43.817Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:43.818Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:43.819Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:43.829Z&#x9;info&#x9;StreamReceiver started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_active&#34;, &#34;host&#34;: &#34;127.0.0.1:7132&#34;, &#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-source-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_receiver.go:148&#34;}&#xA;2024-10-18T13:42:43.829Z&#x9;info&#x9;AdminStreamReplicationMessages started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7134&#34;, &#34;service&#34;: &#34;frontend&#34;, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/frontend/admin_handler.go:1835&#34;}&#xA;2024-10-18T13:42:43.830Z&#x9;info&#x9;StreamSender started.&#x9;{&#34;cluster-name&#34;: &#34;task_queue_repl_standby&#34;, &#34;host&#34;: &#34;127.0.7.1:7132&#34;, &#34;shard-id&#34;: 1, &#34;address&#34;: &#34;127.0.7.1:7132&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;xdc-target-shard-id&#34;: 1, &#34;shard-id&#34;: 1, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/service/history/replication/stream_sender.go:146&#34;}&#xA;2024-10-18T13:42:43.891Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:43.892Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster1&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster2&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;2024-10-18T13:42:43.892Z&#x9;info&#x9;wait for clusters to be synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:170&#34;}&#xA;2024-10-18T13:42:44.033Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;standby&#34;, &#34;xdc-target-cluster&#34;: &#34;active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:44.820Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;task_queue_repl_standby&#34;, &#34;xdc-target-cluster&#34;: &#34;task_queue_repl_active&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:44.893Z&#x9;info&#x9;check if clusters are synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:172&#34;}&#xA;2024-10-18T13:42:44.894Z&#x9;info&#x9;clusters synced&#x9;{&#34;xdc-source-cluster&#34;: &#34;cluster2&#34;, &#34;xdc-target-cluster&#34;: &#34;cluster1&#34;, &#34;logging-call-at&#34;: &#34;/home/runner/work/temporal/temporal/tests/xdc/base.go:196&#34;}&#xA;    history_replication_signals_and_updates_test.go:210: flaky test&#xA;--- SKIP: TestHistoryReplicationSignalsAndUpdatesTestSuite/TestAcceptedUpdateCanBeCompletedAfterFailoverAndFailback (6.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId" time="0.000000">
			<skipped message="=== RUN   TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId&#xA;    history_replication_signals_and_updates_test.go:362: flaky test&#xA;--- SKIP: TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAcceptedUpdateWithConflictingId (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated" time="0.000000">
			<skipped message="=== RUN   TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated&#xA;    nexus_state_replication_test.go:102: flaky test&#xA;--- SKIP: TestNexusStateReplicationTestSuite/TestNexusOperationEventsReplicated (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover" time="0.000000">
			<skipped message="=== RUN   TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover&#xA;    failover_test.go:1951: flaky test&#xA;--- SKIP: TestFuncClustersTestSuite/TestCronWorkflowCompleteAndFailover (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover" time="0.000000">
			<skipped message="=== RUN   TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover&#xA;    failover_test.go:1855: flaky test&#xA;--- SKIP: TestFuncClustersTestSuite/TestCronWorkflowStartAndFailover (0.00s)&#xA;"></skipped>
		</testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestApplyReplicationEventRevivesInUseTombstones" time="8.570000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyAdmittedUpdateWithConflictingId" time="3.090000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionDoesNotReapplyCompleteUpdateWithConflictingId" time="2.640000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionReappliesSignals" time="1.720000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestForceReplicateResetWorkflow_BaseWorkflowNotFound" time="15.530000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataEntriesAreReplicatedOnDemand" time="8.410000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestConflictResolutionReappliesUpdates" time="3.490000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestAdvVisCrossDCTestSuite/TestSearchAttributes" time="18.680000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataIsReplicatedFromActiveToPassive" time="2.610000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite/TestUpdateCompletedAfterFailoverCannotBeCompletedAgainAfterFailback" time="5.190000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestAdvVisCrossDCTestSuite" time="39.660000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataIsReplicatedFromPassiveToActive" time="7.110000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationSignalsAndUpdatesTestSuite" time="43.230000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestReplicateHistoryEvents_ForceReplicationScenario" time="14.680000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite/TestUserDataTombstonesAreReplicated" time="10.180000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamEnabled/TestWorkflowReplicationTaskFailure" time="8.220000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestUserDataReplicationTestSuite" time="58.770000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite/TestResetWorkflow_SyncWorkflowState" time="14.120000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamEnabled" time="20.190000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestStreamBasedReplicationTestSuite" time="64.569000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusCallbackReplicated" time="21.730000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite/TestNexusOperationCancelationReplicated" time="1.720000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/success" time="0.030000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/handler_error" time="0.030000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive/redirect_disabled_by_header" time="0.000000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCancelOperationForwardedFromStandbyToActive" time="8.109000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusStateReplicationTestSuite" time="34.240000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestCompleteOperationForwardedFromStandbyToActive" time="1.370000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamDisabled/TestWorkflowReplicationTaskFailure" time="10.520000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/success" time="0.030000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/operation_error" time="0.030000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/handler_error" time="0.030000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive/redirect_disabled_by_header" time="0.000000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite/TestStartOperationForwardedFromStandbyToActive" time="1.610000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV1ReplicationStreamDisabled" time="23.660000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestNexusRequestForwardingTestSuite" time="26.200000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamEnabled/TestWorkflowReplicationTaskFailure" time="8.790000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestActivityHeartbeatFailover" time="27.360000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamEnabled" time="17.770000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamDisabled/TestWorkflowReplicationTaskFailure" time="10.780000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestContinueAsNewFailover" time="19.430000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite/QueueV2ReplicationStreamDisabled" time="18.710000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestHistoryReplicationDLQSuite" time="80.340000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceMigration_ClosedWorkflow" time="18.650000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceMigration_ResetWorkflow" time="12.550000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestForceWorkflowTaskClose_WithClusterReconnect" time="34.150000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestLocalNamespaceMigration" time="27.160000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestNamespaceFailover" time="16.059000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestResetWorkflowFailover" time="23.640000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestSignalFailover" time="16.250000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestSimpleWorkflowFailover" time="21.920000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestStartWorkflowExecution_Failover_WorkflowIDReusePolicy" time="16.190000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestStickyWorkflowTaskFailover" time="28.740000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestTerminateFailover" time="16.129000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestTransientWorkflowTaskFailover" time="17.210000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestUserTimerFailover" time="17.150000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestWorkflowRetryFailAndFailover" time="16.180000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite/TestWorkflowRetryStartAndFailover" time="17.130000"></testcase>
		<testcase classname="go.temporal.io/server/tests/xdc" name="TestFuncClustersTestSuite" time="356.850000"></testcase>
	</testsuite>
</testsuites>