from typing import Literal
AvailModels = Literal[
	"openai|gpt-4o",
	"openai|gpt-4",
	"openai|chatgpt-4o-latest",
	"openai|gpt-4o-mini",
	"openai|gpt-4-turbo",
	"openai|gpt-4-0613",
	"openai|gpt-3.5-turbo",
	"openai|gpt-4o-realtime-preview",
	"openai|gpt-4o-audio-preview",
	"openai|ft:gpt-3.5-turbo-0125:personal:doktor:8xHAc2HS",
	"openai|gpt-3.5-turbo-0125",
	"openai|gpt-4-turbo-preview",
	"openai|gpt-4-0125-preview",
	"openai|gpt-3.5-turbo-1106",
	"openai|gpt-4-1106-preview",
	"openai|gpt-3.5-turbo-instruct",
	"openai|gpt-3.5-turbo-16k",
	"openai|gpt-4o-2024-08-06",
	"openai|gpt-4o-2024-05-13",
	"openai|gpt-3.5-turbo-instruct-0914",
	"openai|gpt-4o-mini-2024-07-18",
	"openai|gpt-4-turbo-2024-04-09",
	"openai|gpt-4o-audio-preview-2024-10-01",
	"openai|gpt-4o-realtime-preview-2024-10-01",
	"anthropic|claude-3-5-sonnet-20240620",
	"anthropic|claude-3-opus-20240229",
	"anthropic|claude-3-sonnet-20240229",
	"anthropic|claude-3-haiku-20240307",
	"deepseek|deepseek-chat",
	"deepseek|deepseek-coder",
	"deepinfra|microsoft/WizardLM-2-8x22B",
	"deepinfra|meta-llama/Llama-3.2-90B-Vision-Instruct",
	"deepinfra|mistralai/Mistral-7B-Instruct-v0.3",
	"deepinfra|meta-llama/Meta-Llama-3.1-70B-Instruct",
	"deepinfra|meta-llama/Meta-Llama-3.1-8B-Instruct",
	"deepinfra|Qwen/Qwen2.5-72B-Instruct",
	"deepinfra|meta-llama/Llama-3.2-11B-Vision-Instruct",
	"deepinfra|meta-llama/Meta-Llama-3.1-405B-Instruct",
	"ollama|llama3.1:8b-instruct-q6_K",
	"ollama|qwen2.5:latest",
	"ollama|mxbai-embed-large:latest",
	"ollama|bge-m3:latest",
	"ollama|wizardlm2:7b-q6_K",
	"ollama|deepseek-coder-v2:16b",
	"ollama|starcoder2:latest",
	"ollama|codeqwen:latest",
	"ollama|deepseek-coder-v2:16b-lite-instruct-q6_K",
	"ollama|mixbai:latest",
	"ollama|mxbai-embed-large:335m",
	"ollama|phi3:latest"
    "google|gemini-1.5-flash",
    "google|gemini-1.5-pro",
]
