[project]
name = 'oneping'
version = '0.5.6'
description = 'LLM provider abstraction layer.'
readme = { file = 'README.md' , content-type = 'text/markdown' }
authors = [{ name = 'Doug Hanley', email = 'doug@compendiumlabs.ai' }]
license = { text = 'MIT' }
classifiers = [
    'License :: OSI Approved :: MIT License',
    'Programming Language :: Python',
    'Programming Language :: Python :: 3',
]
keywords = ['llm', 'chat']
dependencies = ['aiohttp', 'fire']
requires-python = '>=3.7'

[project.scripts]
oneping = 'oneping.__main__:main'

[project.optional-dependencies]
native = ['openai', 'anthropic', 'fireworks-ai']
chat = ['asyncstdlib', 'textual', 'python-fasthtml']

[project.urls]
Homepage = 'http://github.com/CompendiumLabs/oneping'

[tool.setuptools]
packages = ['oneping', 'oneping.native', 'oneping.interface']

[tool.setuptools.package-data]
"oneping.interface" = ["web/*"]
